% this file is called up by thesis.tex
% content in this file will be fed into the main document
\pagestyle{empty}
%: ----------------------- name of chapter  -------------------------
\chapter{Generadores Minimales}
\label{cap:generadoresMinimales} % top level followed by section, subsection

%: ----------------------- paths to graphics ------------------------

% change according to folder and file names
%\ifpdf
%    \graphicspath{{X/figures/PNG/}{X/figures/PDF/}{X/figures/}}
%\else
%   \graphicspath{{X/figures/EPS/}{X/figures/}}
%\fi

%: ----------------------- contents from here ------------------------


\pagestyle{headings}

\bigdrop{0pt}{5}{cmr10}El sistema de inferencia de \slfde \cite{Enciso2002,Cordero2012} y la salida del algoritmo \cierree se pueden usar para enumerar todos los conjuntos cerrados y todos los generadores minimales a partir de un conjunto de implicaciones y de atributos. Por tanto, el contenido de este capítulo va a estar muy ligado al anterior y muchos de los conceptos van a aparecer nuevamente.

En el capítulo de introducción \ref{cap:introduccion} hablábamos de dos formas de representación del conocimiento: los sistemas de implicaciones y los retículos de conceptos. Asimismo, vimos que existen varios problemas y soluciones en cuanto a extraer ambas representaciones a partir de un \textit{dataset} de entrada. Sin embargo, en este momento vamos a tratar con un problema complementario que permite conectar ambas representaciones del conocimiento: la enumeración de todas los conjuntos cerrados de un conjunto dado de implicaciones. Además, proponemos un método para producir no sólo todos los conjuntos cerrados, sino también, para cada uno de ellos, su representante canónico, denominados generadores minimales.

La importancia de los generadores mínimos está bien justificada por trabajos notables como el profundo estudio de Poelmans et al. \cite{Poelmans2013} o el de Qu et al. \cite{Qu2007}. Por otra parte, han sido utilizados como punto fundamental para construir bases, las cuales constituyen una representación compacta del conocimiento que permite un mejor rendimiento de los métodos de razonamiento basados en reglas \cite{Missaoui2010,Missaoui2012}. Todos los autores mencionados han considerado el \textit{dataset} como la entrada del problema, es decir, los generadores minimales y los conjuntos cerrados se infieren a partir de la información original. En \cite{Hamrouni2007,Nishio2012a} se proponen algunos métodos para resolver este problema.

En nuestro caso, centrándonos una vez más en el tratamiento inteligente de los conjuntos de implicaciones, vamos a utilizarlas como los elementos para describir la información y además, como base del diseño de un método para enumerar todos los conjuntos cerrados y sus generadores minimales a partir de esta información, y no del \textit{dataset} original (como en los trabajos mencionados), lo cual, hasta donde sabemos, no existe trabajo previo al respecto. El nuevo método propuesto utiliza la \slfde y es una evolución de \cite{Cordero2012}. Este método trabaja sobre el conjunto de implicaciones aplicando unas reglas de inferencia y construyendo un espacio de búsqueda de árbol, lo cual como ya adelantamos al principio del capítulo, va a ser muy parecido a los árboles del caso de las claves minimales.

La generación del sistema de implicaciones asociado a un operador de cierre es un problema difícil y el inverso también, teniendo una complejidad exponencial. Por lo tanto, nos vamos a enfocar en la definición de un método para resolver este problema y en el diseño de una implementación más eficiente, particularmente acercándonos al problema utilizando computación paralela.

Por tanto, en este capítulo, tras una relacionar brevemente las implicaciones con los generadores minimales \ref{seccion:implicacionesGeneradoresMinimales}, pasaremos a una sección fundamental donde se exponen cada uno de los métodos analizados e implementados \ref{seccion:metodosGeneradoresMinimales}. Para cada uno de ellos se presenta su definición en forma de algoritmo y se acompaña de un ejemplo ilustrativo de su funcionamiento. Una vez presentados los métodos, en la sección \ref{seccion:resultadosGeneradoresMinimales} se presenta de forma más detallada los pruebas realizadas y los resultados obtenidos por cada método. De forma similar a lo que se presentó para el capítulo de claves, cerrarán el capítulo los experimentos y los resultados obtenidos, esta vez, sobre la arquitectura de computación paralela \ref{seccion:computacionParalelaGeneradoresMinimales}.


\section{Implicaciones y generadores minimales}
\label{seccion:implicacionesGeneradoresMinimales}
Se dice que un sistema de implicaciones es completo para un operador de cierre si captura todo el conocimiento relacionado con ese operador (contexto), es decir, el sistema de implicaciones expresa en el lenguaje de la lógica todo el conocimiento relativo al cierre. Formalmente:

\begin{definicion}
Sea $c\colon 2^M\to 2^M$ un operador de cierre sobre $M$ y $\Sigma\subseteq \mathcal L_M$. El sistema de implicaciones $\Sigma$ se dice que es completo para $c$ si se verifica la siguiente equivalencia:
$$
\forall A\to B\in\mathcal L_M, \quad c\models A\to B\quad\text{si y sólo si }\quad \Sigma\models A\to B
$$
\end{definicion}


De forma inmediata, cuando un sistema de implicaciones $\Sigma$ es completo para un operador de cierre $c$, su operador de cierre sintáctico coincide con $c$, es decir, $X^+_\Sigma = c(X) \ \ \forall X\subseteq M$.

Como hemos mostrado, cualquier operador de cierre $c$ en $M$ puede asociarse con un sistema de implicaciones. Esta conexión establece una forma de gestionar el trabajo del operador de cierre $c$ por medio de su derivación sintáctica y, como consecuencia, se puede elaborar un método para realizar esta gestión. Pero, ¿qué pasa con la conexión inversa? Es decir, dado un conjunto de implicaciones, ¿es posible generar el operador de cierre $c$ asociado a él? Tal pregunta es el núcleo de esta parte de la tesis y su solución implica enumerar todos los conjuntos cerrados.

Si tenemos que $X,Y \subseteq M$ satisfacen que $X = Y^+_\Sigma$, es habitual decir que $Y$ es un generador del conjunto cerrado $X$. Observe que cualquier subconjunto de $X$ que contiene $Y$ es también un generador de $X$. Dado que trabajamos con conjuntos finitos de atributos, el conjunto de los generadores de un conjunto cerrado se pueden caracterizar por sus generadores minimales.

\begin{definicion}[Generador minimal]
Sea $c\colon 2^M\to 2^M$ un operador de cierre, sea $C \subseteq M$ un conjunto cerrado, i.e. $c(C) = C$, y sea $A\subseteq M$. El conjunto $A$ se denomina generador minimal (en adelante, \textit{mingen}) para $C$ con respecto a $c$ si $c(A) = C$ y, $\forall X\subseteq A$, si $c(X) = C$, entonces $X = A$.  
\end{definicion}


\section{Métodos para calcular los generadores minimales}
\label{seccion:metodosGeneradoresMinimales}
En \cite{Cordero2012}, se utilizó la \slfde como herramienta para encontrar todos los generadores minimales a partir de un conjunto de implicaciones. El método emplea la función \ref{algoritmo:Cls} para guiar la búsqueda de nuevos candidatos de generador minimal. Concretamente, dado un conjunto de atributos $M$ y un sistema de implicaciones $\Sigma$, el método realiza un mapeo $mg_\Sigma\colon 2^M\to 2^{2^M}$ que satisface la siguiente condición.

$$\forall X,Y\subseteq M$$

\begin{center}
$X\in mg_\Sigma(C)$ si y sólo si $C$ es cerrado para $(\ )^+_\Sigma$ y $X$ es un generador minimal para $C$.
\end{center}

\begin{ejemplo}
Sea $\Sigma=\{a\to c, bc\to d, c\to ae, d\to e\}$, el mapeo $mg_\Sigma$ se describe como:
\begin{center}
\begin{tabular}{p{1.6cm}|p{.4cm}p{.3cm}p{.3cm}p{.5cm}p{.5cm}p{.6cm}p{.6cm}p{.8cm}p{.9cm}}
$X$ & $\varnothing$ & $b$ & $e$ & $be$ & $de$ & $ace$ & $bde$ &  $acde$ &   $abcde$   \\
\hline
$mg_\Sigma(X)$ &$\varnothing$ & $b$ & $e$ & $be$ & $d$  & $a$ & $bd$ & $ad$ & $ab$ 
\\
& & & & & & $c$& &$cd$ & $bc$    
\end{tabular}
\end{center}

En otro caso, $X$ no es cerrado y $mg_\Sigma(X)=\varnothing$. Nótese que $\varnothing$ es cerrado y $mg_{\Sigma}(\varnothing)=\{\varnothing\}$, i.e. $\varnothing$ es un generador minimal del conjunto cerrado $\varnothing$.
\end{ejemplo}

Los algoritmos que presentamos en esta sección deben usar la siguiente operación para este tipo de mapeos. Dados dos mapeos: $mg_1,mg_2\colon 2^M\to 2^{2^M}$, el mapeo $mg_1\sqcup mg_2\colon 2^M\to 2^{2^M}$ se define como:

$$(mg_1\sqcup mg_2)(X)={\tt Minimals}(mg_1(X)\cup mg_2(X)) \ \ \forall X\subseteq M$$

Por tanto, $Y\in (mg_1\sqcup mg_2)(X)$ sii $Y$ es un conjunto minimal de $mg_1(X)\cup mg_2(X)$ en $(2^M,\subseteq)$, i.e. $Y\in mg_1(X)\cup mg_2(X)$ y no existe otro conjunto de atributos $Z\in mg_1(X)\cup mg_2(X)$ tal que $Z\varsubsetneq Y$.

Finalmente, con lo mostrado en esta sección, ya tenemos todas las herramientas necesarias para definir el método \textit{Minimal Generator}.

\subsection{Método MinGen}
El primer método de cálculo de los generadores minimales que hemos estudiado e implementado se introdujo originalmente en \cite{Cordero2012}. En nuestro caso, para la tesis lo describimos según la función \ref{algoritmo:minGen} y lo acompañamos de un ejemplo de aplicación en \ref{ejemplo:minGenBasico} 

\begin{function}[h]
\caption{MinGen($M$, Label, Guide, $\Sigma$)}
\label{algoritmo:minGen}
\small
\DontPrintSemicolon
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\Input{Conjunto de atributos $M$. \\
Un conjunto auxiliar para construir un generador minimal, Label.\\
Un conjunto auxiliar para construir un conjunto cerrado, Guide.\\ 
Un sistema de implicaciones $\Sigma$ en $M$.}
\Output{El mapeo $mg_\Sigma$.}
\Begin{
	\ForEach{$X\subseteq M$}{
	
		\ \ $mg_\Sigma(X) := \varnothing$
	}
	\vspace{0.2cm}
	(Guide, $\Sigma$) := {\tt Cls}(Guide, $\Sigma$)
	
	$M := M\smallsetminus$Guide
	
	\vspace{0.2cm}
	$\mathrm{Premises} := \{A\subseteq M\mid  A\to B\in \Sigma\text{ for some }B\subseteq M\}$
	ClosedSets$:=\{X\subseteq M\mid A\not\subseteq X \text{ for all }A\in \mathrm{Premises}\}$

	\vspace{0.2cm}
	\ForEach{$X\in \mathrm{ClosedSets}$}{
	
		\ \ $mg_\Sigma(\mathrm{Guide}\cup X) := \{\mathrm{Label}\cup X\}$
	}
	
	\vspace{0.2cm}
	\ForEach{$A\in \mathrm{Premises}$}{
	
		$mg_\Sigma := mg_\Sigma\sqcup\mathrm{MinGen}(M, \mathrm{Label}\cup A, \mathrm{Guide}\cup A, \Sigma)$
	}
	\Return $mg_\Sigma$
}
\end{function}

La entrada de MinGen es un subconjunto de atributos de $M$ y un conjunto de implicaciones $\Sigma$. El resultado es el conjunto de conjuntos cerrados junto con todos los generadores minimlaes que los generan, es decir, $\{\langle C, mg_\Sigma(C)\rangle: C$ es un conjunto cerrado\} donde $mg_\Sigma(C)$ es el conjunto de generadores minimales $D$ que satisfacen $D^+_\Sigma = C$.

\begin{ejemplo}
\label{ejemplo:minGenBasico}
Sea el sistema de implicaciones $\Sigma = \{a\to c, bc\to d, c\to ae, d\to e\}$. La función \ref{algoritmo:minGen}$(abcde,\varnothing,\varnothing,\Sigma)$ devuelve el siguiente resultado:  
\begin{center}
\begin{tabular}{p{1.6cm}|p{.4cm}p{.3cm}p{.3cm}p{.5cm}p{.6cm}p{.8cm}p{.9cm}p{.6cm}p{.8cm}}
$X$ & $\varnothing$ & $b$ & $e$ & $be$& $ace$ &  $acde$ &   $abcde$ & $de$ & $bde$  \\
\hline
$mg_\Sigma(X)$ &$\varnothing$ & $b$ & $e$ & $be$& $a$ & $ad$ & $ab$ & $d$ & $bd$ 
\\
& & &  & & $c$ &$cd$ & $bc$&  &  
\end{tabular}
\end{center}

El árbol de búsqueda que se va generando lo podemos ver en la Figura \ref{figura:arbolMinGenEjemplo} y la traza de ejecución la mostramos a continuación.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics*[width=.95\textwidth,height=.27\textheight]{arbolMinGenEjemplo.png}
	\end{center}
	\caption{Árbol de búsqueda que genera el algoritmo \ref{algoritmo:minGen} para el Ejemplo \ref{ejemplo:minGenBasico}.}
	\label{figura:arbolMinGenEjemplo}
\end{figure}

MinGen$(abcde,\varnothing,\varnothing,\{a\to c, bc\to d, c\to ae, d\to e\})$:
\begin{center}
Cls$(\varnothing,\Sigma)=(\varnothing,\{a\to c, bc\to d, c\to ae, d\to e\})$ y

\begin{tabular}{p{1.6cm}|p{.4cm}p{.3cm}p{.3cm}p{.5cm}}
$X$ & $\varnothing$ & $b$ & $e$ & $be$ \\
\hline
$mg_\Sigma(X)$ &$\varnothing$ & $b$ & $e$ & $be$
\end{tabular}
\end{center}
\begin{enumerate}
\item[1] MinGen$(abcde,a,a,\{a\to c, bc\to d, c\to ae, d\to e\})$:
\begin{center}
Cls$(a,\{a\to c, bc\to d, c\to ae, d\to e\})=(ace,\{ b\to d\})$ y

\begin{tabular}{p{1.6cm}|p{.6cm}p{.6cm}}
$X$ & $ace$ & $acde$ \\
\hline
$mg_{\Sigma_1}(X)$ & $a$ & $ad$
\end{tabular}
\end{center}
\begin{enumerate}
\item[1.1] MinGen$(bd,ab,abce,\{b\to d\})$:
\begin{center}
Cls$(abce,\{b\to d\})=(abcde,\varnothing)$ y

\begin{tabular}{p{1.8cm}|p{.8cm}}
$X$ &  $abcde$ \\
\hline
$mg_{\Sigma_{1.1}}(X)$ & $ab$
\end{tabular}
\end{center}
\end{enumerate}
Volvemos al nivel 1: $mg_{\Sigma_1}:=mg_{\Sigma_1}\sqcup mg_{\Sigma_{1.1}}$ y entonces
\begin{center}
\begin{tabular}{p{1.6cm}|p{.6cm}p{.7cm}p{.8cm}}
$X$ & $ace$ & $acde$ &  $abcde$ \\
\hline
$mg_{\Sigma_1}(X)$ & $a$ & $ad$ & $ab$
\end{tabular}
\end{center}

\end{enumerate}
Volvemos al nivel raiz: $mg_{\Sigma}:=mg_{\Sigma}\sqcup mg_{\Sigma_{1}}$ y 
\begin{center}
\begin{tabular}{p{1.6cm}|p{.4cm}p{.3cm}p{.3cm}p{.5cm}p{.6cm}p{.7cm}p{.8cm}}
$X$ & $\varnothing$ & $b$ & $e$ & $be$& $ace$ & $acde$ &  $abcde$ \\
\hline
$mg_\Sigma(X)$ &$\varnothing$ & $b$ & $e$ & $be$& $a$ & $ad$ & $ab$
\end{tabular}
\end{center}
\begin{enumerate}
\item[2] MinGen$(abcde,bc,bc,\{a\to c, bc\to d, c\to ae, d\to e\})$:
\begin{center}
Cls$(bc,\{a\to c, bc\to d, c\to ae, d\to e\})=(abcde,\varnothing)$

\begin{tabular}{p{1.6cm}|p{.8cm}}
$X$ & $abcde$ \\
\hline
$mg_{\Sigma_2}(X)$ & $bc$
\end{tabular}
\end{center}
\end{enumerate}
Volvemos al nivel raiz: $mg_{\Sigma}:=mg_{\Sigma}\sqcup mg_{\Sigma_{2}}$ y 
\begin{center}
\begin{tabular}{p{1.6cm}|p{.4cm}p{.3cm}p{.3cm}p{.5cm}p{.6cm}p{.8cm}p{.8cm}}
$X$ & $\varnothing$ & $b$ & $e$ & $be$& $ace$ & $acde$ &  $abcde$ \\
\hline
$mg_\Sigma(X)$ &$\varnothing$ & $b$ & $e$ & $be$& $a$ & $ad$ & $ab$
\\
& & &  & &  & & $bc$
\end{tabular}
\end{center}
%=====

\begin{enumerate}
\item[3] MinGen$(abcde,c,c,\{a\to c, bc\to d, c\to ae, d\to e\})$:
\begin{center}
Cls$(c,\{a\to c, bc\to d, c\to ae, d\to e\})=(ace,\{ b\to d \})$ anyd

\begin{tabular}{p{1.6cm}|p{.6cm}p{.6cm}}
$X$ & $ace$ & $acde$ \\
\hline
$mg_{\Sigma_3}(X)$ & $c$ & $cd$
\end{tabular}
\end{center}
\begin{enumerate}
\item[3.1] MinGen$(bd,bc,abce,\{b\to d\})$:
\begin{center}
Cls$(abce,\{b\to d\})=(abcde,\varnothing)$ y

\begin{tabular}{p{1.8cm}|p{.8cm}}
$X$ &  $abcde$ \\
\hline
$mg_{\Sigma_{3.1}}(X)$ & $bc$
\end{tabular}
\end{center}
\end{enumerate}
Volvemos al nivel 3: $mg_{\Sigma_3}:=mg_{\Sigma_3}\sqcup mg_{\Sigma_{3.1}}$ y entonces
\begin{center}
\begin{tabular}{p{1.6cm}|p{.6cm}p{.8cm}p{.8cm}}
$X$ & $ace$ & $acde$ &  $abcde$\\
\hline
$mg_{\Sigma_3}(X)$ & $c$ & $cd$& $bc$
\end{tabular}
\end{center}
\end{enumerate}
Volvemos al nivel raiz: $mg_{\Sigma}:=mg_{\Sigma}\sqcup mg_{\Sigma_{3}}$ y 
\begin{center}
\begin{tabular}{p{1.6cm}|p{.4cm}p{.3cm}p{.3cm}p{.5cm}p{.6cm}p{.8cm}p{.9cm}}
$X$ & $\varnothing$ & $b$ & $e$ & $be$& $ace$ &  $acde$ &   $abcde$   \\
\hline
$mg_\Sigma(X)$ &$\varnothing$ & $b$ & $e$ & $be$& $a$ & $ad$ & $ab$ 
\\
& & &  & & $c$ &$cd$ & $bc$
\end{tabular}
\end{center}

%=====
\begin{enumerate}
\item[4] MinGen$(abcde,d,d,\{a\to c, bc\to d, c\to ae, d\to e\})$:

\begin{center}
Cls$(d,\{a\to c, bc\to d, c\to ae, d\to e\})=(de,\{a\to c, c\to a\})$ y

\begin{tabular}{p{1.6cm}|p{.6cm}p{.6cm}}
$X$ & $de$ & $bde$ \\
\hline
$mg_{\Sigma_4}(X)$ & $d$ & $bd$
\end{tabular}
\end{center}
\begin{enumerate}
\item[4.1] MinGen$(abc,ad,ade,\{a\to c, c\to a\})$:

\begin{center}
Cls$(ade,\{a\to c, c\to a\})=(acde,\varnothing)$ y

\begin{tabular}{p{1.8cm}|p{.8cm}p{.8cm}}
$X$ &  $acde$&  $abcde$ \\
\hline
$mg_{\Sigma_{4.1}}(X)$ & $ad$& $abd$
\end{tabular}
\end{center}
\end{enumerate}
Volvemos al nivel 4: $mg_{\Sigma_4}:=mg_{\Sigma_4}\sqcup mg_{\Sigma_{4.1}}$ y entonces
\begin{center}
\begin{tabular}{p{1.6cm}|p{.6cm}p{.6cm}p{.8cm}p{.8cm}}
$X$ & $de$ & $bde$ &  $acde$&  $abcde$ \\
\hline
$mg_{\Sigma_4}(X)$ & $d$ & $bd$ & $ad$& $abd$
\end{tabular}
\end{center}
\begin{enumerate}
\item[4.2] MinGen$(abc,cd,cde,\{a\to c, c\to a\})$:
\begin{center}
Cls$(cde,\{a\to c, c\to a\})=(acde,\varnothing)$ y

\begin{tabular}{p{1.8cm}|p{.8cm}p{.8cm}}
$X$ &  $acde$&  $abcde$ \\
\hline
$mg_{\Sigma_{4.2}}(X)$ & $cd$& $cbd$
\end{tabular}
\end{center}
\end{enumerate}
Volvemos al nivel 4: $mg_{\Sigma_4}:=mg_{\Sigma_4}\sqcup mg_{\Sigma_{4.2}}$ y entonces
\begin{center}
\begin{tabular}{p{1.6cm}|p{.5cm}p{.6cm}p{.8cm}p{.8cm}}
$X$ & $de$ & $bde$ &  $acde$&  $abcde$ \\
\hline
$mg_{\Sigma_4}(X)$ & $d$ & $bd$ & $ad$& $abd$ 
\\
 &  & & $cd$& $cbd$ 
\end{tabular}
\end{center}
\end{enumerate}
Volvemos al nivel raiz: $mg_{\Sigma}:=mg_{\Sigma}\sqcup mg_{\Sigma_{4}}$ y efectivamente, obtenemos el resultado que habíamos adelantado
\begin{center}
\begin{tabular}{p{1.6cm}|p{.4cm}p{.3cm}p{.3cm}p{.5cm}p{.6cm}p{.8cm}p{.9cm}p{.6cm}p{.8cm}}
$X$ & $\varnothing$ & $b$ & $e$ & $be$& $ace$ &  $acde$ &   $abcde$ & $de$ & $bde$  \\
\hline
$mg_\Sigma(X)$ &$\varnothing$ & $b$ & $e$ & $be$& $a$ & $ad$ & $ab$ & $d$ & $bd$ 
\\
& & &  & & $c$ &$cd$ & $bc$&  &  
\end{tabular}
\end{center}
\end{ejemplo}

\begin{ejemplo}
\label{ejemplo:minGenGrande}
Sea el conjunto de atributos $M = \{1, 2, 3, 4, 5\}$ y sea el sistema de implicaciones $\Sigma = \{5\to 4, 2\ 3\to 4, 2\ 4\to 3, 3\ 4\to 2, 1\ 4\to 2\ 3\ 5, 2\ 5\to 1\ 3\ 4, 3\ 5\to 1\ 2\ 4, 1\ 5\to 2\ 4, 1\ 2\ 3\to 4\ 5\}$. La función \ref{algoritmo:minGen}$(M,\varnothing,\varnothing,\Sigma)$ genera el árbol de búsqueda que muestra la Figura \ref{figura:arbolMinGenEjemploGrande} en el que los generadores minimales obtenidos están sombreados en color gris.  

\begin{figure}[htbp]
	\begin{center}
		\includegraphics*[width=1\textwidth,height=.7\textheight]{arbolMinGenEjemploGrande.png}
	\end{center}
	\caption{Árbol de búsqueda que genera el algoritmo \ref{algoritmo:minGen} para el Ejemplo \ref{ejemplo:minGenGrande}.}
	\label{figura:arbolMinGenEjemploGrande}
\end{figure}
\end{ejemplo}

El punto clave del algoritmo MinGen recae en el uso del cierre \cierree ya que utiliza las ventajas de la información adicional que proporciona, es decir, \cierree se usa no sólo para calcular generadores de conjuntos cerrados sino también conjuntos de implicaciones más pequeños que nos guían en la búsqueda de nuevos subconjuntos que resulten en generadores minimales.



\subsection{Método MinGenPr}
En esta sección presentamos una variante más avanzada del método MinGen anterior. Para ello, hemos incorporado un mecanismo de poda para evitar la generación de generadores minimales y cierres redundantes. El propósito de esta poda es verificar la información de cada nodo en el espacio de búsqueda, evitando la apertura de una rama completa. Esta reducción sólo puede llevarse a cabo si podemos garantizar que toda la información relativa a los generaciones minimales se genera en otras ramas. En la función \ref{algoritmo:minGenPr} esta estrategia de poda se implementa en la línea número \#1. Por lo tanto, para garantizar que la información generada en una rama sea supérflua, diseñamos una poda basada en el test de inclusión de conjuntos que involucra a todos los nodos del mismo nivel. En la Figura 2, se ilustra cómo funciona esta estrategia de poda aplicada al siguiente ejemplo:

\begin{function}[h]
\caption{MinGenPr($M$, Label, Guide, $\Sigma$)}
\label{algoritmo:minGenPr}
\small
\DontPrintSemicolon
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\Input{Conjunto de atributos $M$. \\
Un conjunto auxiliar para construir un generador minimal, Label.\\
Un conjunto auxiliar para construir un conjunto cerrado, Guide.\\ 
Un sistema de implicaciones $\Sigma$ en $M$.}
\Output{El mapeo $mg_\Sigma$.}
\Begin{
	\ForEach{$X\subseteq M$}{
	
		\ \ $mg_\Sigma(X) := \varnothing$
	}
	\vspace{0.2cm}
	(Guide, $\Sigma$) := {\tt Cls}(Guide, $\Sigma$)
	
	$M := M\smallsetminus$Guide
	
	\vspace{0.2cm}
	$\mathrm{Premises} := {\tt Minimals}\{A\subseteq M\mid  A\to B\in \Sigma\text{ for some }B\subseteq M\}$
	ClosedSets$:=\{X\subseteq M\mid A\not\subseteq X \text{ for all }A\in \mathrm{Premises}\}$

	\vspace{0.2cm}
	\ForEach{$X\in \mathrm{ClosedSets}$}{
	
		\ \ $mg_\Sigma(\mathrm{Guide}\cup X) := \{\mathrm{Label}\cup X\}$
	}
	
	\vspace{0.2cm}
	\ForEach{$A\in \mathrm{Premises}$}{
	
		$mg_\Sigma := mg_\Sigma\sqcup\mathrm{MinGenPr}(M, \mathrm{Label}\cup A, \mathrm{Guide}\cup A, \Sigma)$
	}
	\Return $mg_\Sigma$
}
\end{function}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics*[width=.95\textwidth,height=.27\textheight]{arbolMinGenPr.png}
	\end{center}
	\caption{Árbol de búsqueda que genera el algoritmo \ref{algoritmo:minGenPr} para el Ejemplo \ref{ejemplo:minGenBasico}.}
	\label{figura:arbolMinGenEjemplo}
\end{figure}


\begin{ejemplo}
\label{ejemplo:minGenPr}
Supongamos el mismo árbol de búsqueda que obteníamos en el Ejemplo \ref{ejemplo:minGenBasico}. La función \ref{algoritmo:minGenPr} $(abcde, \varnothing, \varnothing, \{a\to c, bc \to d, c \to ae , d \to e \}) $ aplica una estrategia de poda evitando abrir la rama cuya etiqueta es un superconjunto de otra rama en el mismo nivel. En concreto, la rama etiquetada $bc$ no se abre porque no es minimal en el conjunto $\{a, bc, c, d\} $. La Figura \ref{figura:arbolMinGenEjemplo} muestra el árbol de búsqueda delineando en gris la rama podada. En el Ejemplo \ref{ejemplo:minGenBasico} esta rama podada corresponde al ítem 2 de la traza mostrada.
\end{ejemplo}




\subsection{Método GenMinGen}
Finalmente, en este caso proponemos una generalización de la estrategia de poda anterior al considerar el test de inclusión del subconjunto no sólo con la información de los nodos del mismo nivel, sino también con todos los generadores minimales calculados antes de la apertura de cada rama. Un paso más allá en esta estrategia de poda es aprovechar los generadores minimales ya calculados para aumentar el número de ramas que no es necesario abrir. Como muestra la función \ref{algoritmo:GenMinGen}, consideramos esta poda general en la línea \#1, y después, en la línea \#2 se construye la lista de premisas minimales consideradas en cada etapa.

\begin{function}[h]
\caption{GenMinGen($M$, Label, Guide, $\Sigma$)}
\label{algoritmo:GenMinGen}
\small
\DontPrintSemicolon
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\Input{Conjunto de atributos $M$. \\
Un conjunto auxiliar para construir un generador minimal, Label.\\
Un conjunto auxiliar para construir un conjunto cerrado, Guide.\\ 
Un sistema de implicaciones $\Sigma$ en $M$.}
\Output{El mapeo $mg_\Sigma$.}
\Begin{
	\ForEach{$X\subseteq M$}{
	
		\ \ $mg_\Sigma(X) := \varnothing$
	}
	\vspace{0.2cm}
	(Guide, $\Sigma$) := {\tt Cls}(Guide, $\Sigma$)
	
	$M := M\smallsetminus$Guide
	
	\vspace{0.2cm}
	$\mathrm{Premises} := {\tt Minimals}\{A\subseteq M\mid  A\to B\in \Sigma\text{ for some }B\subseteq M\}$
	ClosedSets$:=\{X\subseteq M\mid A\not\subseteq X \text{ for all }A\in \mathrm{Premises}\}$

	\vspace{0.2cm}
	\ForEach{$X\in \mathrm{ClosedSets}$}{
	
		\ \ $mg_\Sigma(\mathrm{Guide}\cup X) := \{\mathrm{Label}\cup X\}$
	}
	
	\vspace{0.2cm}
	\ForEach{$A\in \mathrm{Premises}$}{
	
		\nlset{[\#1]}   \If{there no exists $Y\in$ {\rm MinGenList} such that $Y\subseteq A$}{
	
												$mg_\Sigma := mg_\Sigma\sqcup \mathrm{MinGenPr}(M,\mathrm{Label}\cup A,\mathrm{Guide}\cup A,\Sigma,\mathrm{MinGenList})$
										}
	}
	\nlset{[\#2]}
	\textbf{add} $A$ \textbf{to} MinGenList
	
	\Return $mg_\Sigma$
}
\end{function}

En la Figura \ref{figura:arbolGenMinGen} representamos el espacio de búsqueda correspondiente a la aplicación de la función \ref{algoritmo:GenMinGen} sobre el Ejemplo \ref{ejemplo:minGenBasico}. Hay que percatarse de que las ramas etiquetadas con $ad$ y $cd$ no se abren porque en el nivel anterior las etiquetas $a$ y $c$ ya se abrieron. En la salida de la función \ref{algoritmo:GenMinGen} los generadores minimales $ad$ y $cd$ aparecen en ramas anteriores mientras que $abd$ y $cbd$ no se computan porque no son realmente generadores minimales. Para verificarlo, podemos fijarnos en los ítems 4.1 y 4.2 de la traza de ejecución del Ejemplo \ref{ejemplo:minGenBasico} que corresponden a ramas superfluas.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics*[width=.95\textwidth,height=.27\textheight]{arbolGenMinGen.png}
	\end{center}
	\caption{Árbol de búsqueda que genera el algoritmo \ref{algoritmo:GenMinGen} para el Ejemplo \ref{ejemplo:minGenBasico}.}
	\label{figura:arbolGenMinGen}
\end{figure}



\section{Experimentos y resultados}
\label{seccion:resultadosGeneradoresMinimales}
En las secciones anteriores hemos presentado el método original de cálculo de generadores minimales \ref{algoritmo:minGen} junto con las dos mejoras de poda, \ref{algoritmo:minGenPr} y \ref{algoritmo:GenMinGen}, y se ha mostrado un ejemplo completo de ejecución. Ahora, presentamos una comparación global del rendimiento
logrado por cada uno de ellos.

Para ello, hemos desarrollado las implementaciones correspondientes para emplear los métodos sobre una batería de conjuntos de implicaciones generadas aleatoriamente. En aras de facilitar la legibilidad y el seguimiento de la comparativa realizada, acompañaremos los resultados obtenidos con varias tablas y gráficas.

Para evaluar esta comparación, vamos a utilizar dos métricas diferentes, el tiempo de ejecución del algoritmo y el número de nodos en el árbol de búsqueda generado por el método. La razón de esta selección es idéntica a la expuesta para el caso de las claves minimales \ref{seccion:experimentosResultados} y que resumimos brevemente. El tiempo de ejecución surge como la medida clásica para probar el rendimiento, pero siempre está estrechamente relacionado con los recursos con los que estamos trabajando. El número de nodos del árbol representa una medida de la magnitud del problema y es independiente de la arquitectura hardware utilizada. Asimismo, debido a la naturaleza intrínseca del tiempo de ejecución, cada experimento ha sido repetido varias veces para poder obtener valores medios fiables.

Para este experimento, en el que vamos a utilizar las implementaciones secuenciales de los algoritmos, todavía no es necesario hacer uso de recursos de supercomputación dado que los resultados se alcanzan en tiempos razonables. Entonces, la arquitectura hardware utilizada en este caso es: Intel(R) Core(TM) i7-6700HQ CPU 2.60Ghz, 8 Gb memoria RAM, ejecutándose sobre Windows 10.

Hemos generado una batería de pruebas con diferentes entradas para evaluar la implementación secuencial y poder mostrar las mejoras de la poda de los métodos desarrollados. En concreto, el experimento se va a realizar sobre los siguientes dos tipos de conjuntos de datos:

\begin{itemize}
	\item Datos aleatorios. Hemos generado cinco ficheros de prueba, cada uno de ellos con 50 implicaciones construidas usando 50 atributos diferentes posibles. Las implicaciones se generan aleatoriamente. 
	\item Datos reales. Hemos generado un fichero con información real tomada a partir de los datos almacenados en \textit{datasets} que podemos encontrar en la web como es el caso de los MovieLens \textit{datasets}\footnote{https://grouplens.org/datasets/movielens/} que se han usado en otras ocasiones en campos como la educación, investigación o industria \cite{Harper2016}. Entraremos en más detalles en relación a estos \textit{datasets} cuando lleguemos a la sección \ref{seccion:movieLensDatasets}, pero para completar la explicación de los ficheros de entrada de este experimento, podemos adelantar que vamos a tratar con un fichero cuyos atributos son los diferentes géneros cinematográficos almacenados en el \textit{dataset} de MovieLens (e.g. Acción, Aventura, Thriller, Comedia, ...) con un total de 19 atributos, y cuyas implicaciones serán relaciones entre ellos que nos proporcionan un conjunto $\Sigma$ final con un total de 245 implicaciones, lo cual supera sustancialmente el test aleatorio.
\end{itemize}

Dicho eso, podemos ver los resultados de los experimentos en  la Figura \ref{figura:experimentosSecuencial} y en la Tabla \ref{tabla:secuencial}, que está organizada en cuatro columnas cuya razón desglosamos a continuación:
\begin{enumerate}
	\item Identificador del archivo de entrada y el método utilizado para resolver.
	\item Tiempo de ejecución (en segundos).
	\item Número de nodos del árbol generado; nos da una indicación del tamaño del problema.
	\item Número de generadores minimales obtenidos.
\end{enumerate}

\begin{table}[htbp]
\scriptsize
	\centering
\caption{Resultados obtenidos por los métodos de generadores minimales en su implementación secuencial.}
\begin{tabular}{lrrrrrr}
%\hline\noalign{\smallskip}
% & Attrib & Implications \\
% & 50 & 50   \\
\noalign{\smallskip}\hline\noalign{\smallskip}
Problema y Método & Total$_{t}$(s) & Nodos & MinGens \\
\noalign{\smallskip}\hline\noalign{\smallskip}
sequential-1-MinGen & 489 & 35.062 & 1.437\\
sequential-1-MinGenPr & 108 & 7.734 & 1.437 \\
sequential-1-GenMinGen & 97 & 6.714 & 1.437 \\
\noalign{\smallskip}\hline\noalign{\smallskip}
sequential-2-MinGen & 53 & 32.408 & 271 \\
sequential-2-MinGenPr & 8 & 4.670 & 271 \\
sequential-2-GenMinGen & 7 & 3.922 & 271 \\
\noalign{\smallskip}\hline\noalign{\smallskip}
sequential-3-MinGen & 41 & 7.518 & 688 \\
sequential-3-MinGenPr & 9 & 1.642 & 688 \\
sequential-3-GenMinGen & 9 & 1.611 & 688 & \\
\noalign{\smallskip}\hline\noalign{\smallskip}
sequential-4-MinGen & 693 & 52.067 & 1.444 \\
sequential-4-MinGenPr & 179 & 12.802 & 1.444 \\
sequential-4-GenMinGen & 148 & 11.014 & 1.444 \\
\noalign{\smallskip}\hline\noalign{\smallskip}
sequential-5-MinGen & 10.647 & 496.521 & 2.941 \\
sequential-5-MinGenPr & 1.897 & 72.470 & 2.941 \\
sequential-5-GenMinGen & 1.071 & 42.957 & 2.941 \\
\noalign{\smallskip}\hline\noalign{\smallskip}
MovieLens10M-MinGen & 980 & 254.170 & 2.681 \\
MovieLens10M-MinGenPr & 210 & 19.187 & 2.681 \\
MovieLens10M-GenMinGen & 198 & 18.926 & 2.681 \\
\noalign{\smallskip}\hline
\end{tabular}
\label{tabla:secuencial}
\end{table}

\begin{figure}[htbp]
	\centering
		\includegraphics*[width=.85\textwidth,height=.3\textheight]{sequentialExperimentsHorizontal.png}
	\caption{Resultados de tiempos de ejecución (a) y número de nodos (b) para el experimento con las implementaciones secuenciales de los métodos. Se ha aplicado escala logarítmica a los ejes con la intención de favorecer la visibilidad de los resultados.}
	\label{figura:experimentosSecuencial}
\end{figure}

A la luz de los resultados obtenidos, se aprecia fácilmente como las estrategias de poda reducen significativamente tanto el número de nodos como el tiempo de ejecución. Mención especial requiere el experimento `secuencial-5' ya que muestra cómo ambas métricas se han reducido drásticamente. El tiempo de ejecución se ha reducido de más de 10.000 segundos a menos de 2.000 segundos. Además, también es considerable la reducción con respecto al número de nodos que conlleva una menor necesidad de recursos en términos de memoria y almacenamiento. Finalmente, como era de prever, MinGen es superado por MinGenPr, y a su vez GenMinGen mejora este último. 

Los resultados obtenidos son prometedores, pero una vez más recordemos que estamos tratando con una cantidad de información de entrada que, en otras ocasiones puede ser mucho más abundante. Por tanto, al igual que en el caso de las claves minimales, vamos a dar un paso más allá abordando el problema del cálculo de los generadores minimales con una estrategia paralela que nos permita aumentar el tamaño de los \textit{datasets} a la entrada.


\section{Computación paralela y generadores minimales}
\label{seccion:computacionParalelaGeneradoresMinimales}
Hasta ahora, ya hemos mostrado las mejoras alcanzadas por las estrategias de poda dentro de los métodos de generadores minimales. Sin embargo, una vez que llega el momento de utilizar estos métodos sobre entradas de mayor tamaño, podemos deducir, a la luz de los resultados obtenidos, que los tiempos de ejecución de los métodos secuenciales serían difícilmente admisibles. No obstante, teniendo en cuenta que cada rama del árbol creado por los métodos constituye un problema en sí mismo, podemos pensar en resolverlos simultáneamente utilizando diferentes recursos. Esta visión del problema sobre una ejecución paralela, proporcionada por los métodos basados en la lógica, da lugar a desarrollar una nueva versión paralela del método de generadores minimales.

Aunque \ref{algoritmo:GenMinGen} ha demostrado tener un mejor rendimiento que \ref{algoritmo:minGenPr} (y ambos a su vez un mejor rendimiento que \ref{algoritmo:minGen}), sólo vamos a desarrollar una versión paralela del método \ref{algoritmo:minGenPr}, que denominaremos \textit{MinGenPar}. Esto se debe al hecho de que no hay necesidad de comunicación entre los subproblemas cuando se usa el método \ref{algoritmo:minGenPr}. Sin embargo, cuando se usa \ref{algoritmo:GenMinGen}, recordemos que la poda aplicada depende de los resultados obtenidos previamente en cada subproblemas, ya que en cada paso, tenemos que comparar con el conjunto actual de generadores minimales generados hasta el momento. Esto rompe la filosofía \textit{MapReduce} de nuestra implementación, donde cada nodo del árbol (es decir, cada subproblema) está destinado a ser resuelto de forma independiente y sin existir comunicación entre los nodos del árbol.

No obstante, incluso teniendo en cuenta que los mejores resultados entre los métodos de generadores minimales son los logrados por \ref{algoritmo:GenMinGen}, al introducir ahora la estrategia paralela, cambian las tornas. En efecto, los resultados de los métodos en su forma secuencial, incluso para \ref{algoritmo:GenMinGen} no pueden compararse con los números que podemos alcanzar cuando usamos computación paralela con \ref{algoritmo:minGenPr}. La computación paralela nos brinda la posibilidad de tratar con problemas de gran tamaño, lo cual es, en la mayoría de los casos, más valioso que posibles mejoras desarrolladas en versiones secuenciales.

Antes de continuar, debemos señalar que los recursos y la arquitectura concreta que se ha utilizado para ejecutar los experimentos paralelos es, una vez más, la que nos aporta el Centro de Supercomputación y Bioinnovación de la Universidad de Málaga\footnote{https://www.scbi.uma.es/}. En particular, para este experimento, hemos utilizado 32 nodos cluster SL230, contando con 16 núcleos y 64GB de memoria RAM y 7 nodos cluster DL980, contando con 80 núcleos y 2TB de memoria RAM. Las comunicaciones se realizan a través de una red Infiniband Net FDR y QDR. En el momento de la ejecución de las pruebas, cada uno de los núcleos está reservado, de forma exclusiva, para nuestro experimento.

\subsection{Algoritmo paralelo: \textit{MinGenPar}}
\label{seccion:algoritmoParalelo}
La implementación paralela del método de cálculo de generadores minimales \textit{MinGenPar} se ha desarrollado siguiendo el marco introducido por los autores en \cite{Benito-Picazo2016} y que es exactamente el mismo que el definido para el caso del cálculo de las claves minimales \ref{seccion:implementacion}. De forma breve, la implementación paralela se lleva a cabo en dos etapas, siguiendo el paradigma \textit{MapReduce} \cite{Dean2004}. 

La primera etapa divide el problema de entrada en varios subproblemas equivalentes pero reducidos de la siguiente forma. Se utiliza un solo núcleo para construir el espacio de búsqueda hasta que se alcanza un cierto nivel de profundidad del árbol. El objetivo es dividir el problema original en varios problemas que puedan ser tratados por múltiples núcleos, desempeñando el papel de un procedimiento \textit{Map}. El proceso continúa hasta que el tamaño del nodo actual sea inferior a un tamaño determinado $\beta$ respecto al número de implicaciones.

En la segunda etapa cada uno de estos subproblemas se resuelve en paralelo usando múltiples núcleos hasta que lleguemos a las hojas del árbol de búsqueda. Como último paso, se utiliza un solo núcleo para componer el resultado global, mezclando los diferentes resultados parciales de cada subproblema en uno final (etapa \textit{Reduce}). Este paso es imprescindible para eliminar redundancias y por tanto, obtener los generadores \textit{minimales}. Podemos ver un esquema gráfico del proceso en la Figura \ref{figura:arquitecturaMapReduce} y el pseudocódigo de la implementación \textit{MinGenPar} en \ref{algoritmo:funcionMinGenPar}.

\begin{figure}[htbp]
	\centering
		\includegraphics*[width=1\textwidth,height=.5\textheight]{arquitecturaMapReduce.png}
	\caption{Esquema de funcionamiento de la implementación paralela de los métodos de generadores minimales utilizando el paradigma \textit{MapReduce} \cite{Dean2004}.}
	\label{figura:arquitecturaMapReduce}
\end{figure}

\begin{function}[h]
\caption{MinGenPar($M$,Label,Guide,$\Sigma$,BOV) }
\label{algoritmo:funcionMinGenPar}
\small
\DontPrintSemicolon
\SetKwFor{If}{If}{then do in parallel}{end}
\SetKwInOut{Input}{input}
\SetKwInOut{Output}{output}
\Input{Conjunto de atributos $M$. \\
Un conjunto auxiliar para construir un generador minimal, Label.\\
Un conjunto auxiliar para construir un conjunto cerrado, Guide.\\ 
Un sistema de implicaciones $\Sigma$ en $M$.\\
BOV: Break of Value for the splitting stage}
\Output{El mapeo $mg_\Sigma$}
\Begin{
\lForEach{$X\subseteq M$}{
	$mg_\Sigma(X):=\varnothing$
	}
(Guide,$\Sigma$):={\tt Cls}(Guide,$\Sigma$)\;
$M:=M\smallsetminus$Guide\;
$
\mathrm{Premises}:={\tt Minimals}\{A\subseteq M\mid  A\to B\in \Sigma\text{ for some }B\subseteq M\}
$\;
ClosedSets$:=\{X\subseteq M\mid A\not\subseteq X \text{ for all }A\in \mathrm{Premises}\}$\;
\lForEach{$X\in \mathrm{ClosedSets}$}{
	$mg_\Sigma(\mathrm{Guide}\cup X):=\{\mathrm{Label}\cup X\}$
	}
%Compute $BOV= \mid \Sigma \mid $\;
\If{$\mid \Sigma \mid \leq BOV$ }{ 
\tcp{[MAP]} \ForEach{$A\in \mathrm{Premises}$}{ \tcp{[REDUCE]} 
	$mg_\Sigma:=mg_\Sigma\sqcup\mathrm{MinGenRd}(M,\mathrm{Label}\cup A,\mathrm{Guide}\cup A,\Sigma)$
}
\Return $mg_\Sigma$
}\Else{
\tcp{[Splitting stage]}\ForEach{$A_k\in \mathrm{Premises}$}{
	$mg_\Sigma^k = \mathrm{MinGenRdPar}(M,\mathrm{Label}\cup A_k,\mathrm{Guide}\cup A_k,\Sigma,BOV)$
}
\ForAll{$mg_\Sigma^k$}{
\tcp{[REDUCE]}$mg_\Sigma:=mg_\Sigma\sqcup mg_\Sigma^k$\;
}
\Return $mg_\Sigma$
}%end else
}

\end{function}

Para demostrar la mejora al pasar de la implementación secuencial a la paralela, esta vez vamos a realizar una serie de experimentos donde los archivos de entrada que vamos a usar van a alcanzar valores mucho mayores que para la prueba secuencial, concretamente, contarán con hasta 150 atributos y 150 implicaciones. 

No obstante, podemos comprobar que incluso con estos números, tres veces más altos que el experimento secuencial, la versión paralela nos reporta resultados en un tiempo admisible y que sobrepasan ampliamente a los obtenidos por su homóloga secuencial, como podemos observar en los valores recogidos en la Tabla \ref{tabla:comparacionMinGenPrSEQPAR}.

\begin{table}[htbp]
\scriptsize
	\centering
\caption{Comparación entre las versiones secuencial y paralela del algoritmo MinGenPar aplicado a problemas de gran tamaño.}
\label{tabla:comparacionMinGenPrSEQPAR}
\begin{tabular}{lrrrrrr}
%\hline\noalign{\smallskip}
% & Attrib & Implications & BOV & Cores & \\
% & 150 & 150 & 140 & 32 &  \\
\noalign{\smallskip}\hline\noalign{\smallskip}
Problema \& Método  & Subp & División$_{t}$(s) & Paralelo$_{t}$(s) & Total$_{t}$(s) & Nodos & MinGens\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-1-sequential & - & - & - & 43 & 374 & 216\\
\cellcolor{gray!25}MinGenPar-1-parallel & 11 & 3 & 1 & \cellcolor{gray!25}4 & 374 & 216\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-2-sequential & - & - & - & 17.352 & 54.375 & 6.273\\
\cellcolor{gray!25}MinGenPar-2-parallel & 347 & 220 & 55 & \cellcolor{gray!25}275 & 54.375 & 6.273\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-3-sequential & - & - & - & 33.338 & 68.531 & 6.529\\
\cellcolor{gray!25}MinGenPar-3-parallel & 822 & 2.338 & 251 & \cellcolor{gray!25}2.589 & 68.531 & 6.529\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-4-sequential & - & - & - & 4.612 & 25.477 & 2.478\\
\cellcolor{gray!25}MinGenPar-4-parallel & 344 & 350 & 97 & \cellcolor{gray!25}447 & 25.477 & 2.478\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-5-sequential & - & - & - & 1.585 & 12.522 & 1.159\\
\cellcolor{gray!25}MinGenPar-5-parallel & 168 & 432 & 30 & \cellcolor{gray!25}462 & 12.522 & 1.159\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-6-sequential & - & - & - & 1.653 & 8.110 & 1.436\\
\cellcolor{gray!25}MinGenPar-6-parallel & 79 & 35 & 7 & \cellcolor{gray!25}42 & 8.110 & 1.436\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-7-sequential & - & - & - & 107.238 & 262.621 & 9.113\\
\cellcolor{gray!25}MinGenPar-7-parallel & 1.754 & 958 & 242 & \cellcolor{gray!25}1.200 & 262.621 & 9.113\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-8-sequential & - & - & - & 61.381 & 257.267 & 5.538\\
\cellcolor{gray!25}MinGenPar-8-parallel & 966 & 253 & 188 & \cellcolor{gray!25}441 & 257.267 & 5.538\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-9-sequential & - & - & - & 372 & 1.726 & 683\\
\cellcolor{gray!25}MinGenPar-9-parallel & 24 & 7 & 2 & \cellcolor{gray!25}9 & 1.726 & 683\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-10-sequential & - & - & - & 7.484 & 45.962 & 2.969\\
\cellcolor{gray!25}MinGenPar-10-parallel & 277 & 186 & 65 & \cellcolor{gray!25}251 & 45.962 & 2.969\\
\noalign{\smallskip}\hline
\end{tabular}
\end{table}

La información mostrada en la Tabla \ref{tabla:comparacionMinGenPrSEQPAR} sigue la misma estructura que la Tabla \ref{tabla:secuencial}, pero esta vez, debido a la estrategia paralela, se introducen nuevos parámetros. Por un lado, el encabezado incluye el número de atributos e implicaciones, el valor de parada (BOV) y la cantidad de núcleos utilizados. Por otro lado, el cuerpo de la tabla contiene seis columnas con la información de los valores del método que desglosamos a continuación:

\begin{enumerate}
	\item Nombre del problema y el método utilizado para resolverlo.
	\item Número de subproblemas generados en la etapa primera del algoritmo.
	\item Tiempo transcurrido para la etapa primera.
	\item Tiempo total de ejecución (etapa parcial + etapa paralela).
	\item Número de nodos del árbol.
	\item Número de generadores minimales obtenidos.
\end{enumerate}

Optamos por mantener el número de nodos y la cantidad de generadores minimales en la tabla solamente con la intención de tener una idea del tamaño del problema, ya que es obvio que ambos implementaciones logran los mismos números.

Como conclusión, gracias a la aplicación de la implementación paralela, se han podido reducir los tiempos de ejecución de horas y días (experimentos `MinGenPr-\{2,3,7,8,10\}-secuencial') a sólo unos pocos minutos. En otras palabras, la computación paralela nos permite tratar con conjuntos de datos de gran tamaño dentro de unos márgenes de tiempo admisibles. No obstante, hay dos aspectos fundamentales que merecen un estudio propio: el cálculo del valor de corte o \textit{BOV} y la estimación del número idóneo de cores a utilizar en los experimentos; a ellos dedicamos los siguientes apartados.


\subsection{Cálculo del valor de corte o \textit{BOV}}
\label{seccion:calculoBOV}
Para el caso de los generadores minimales nos encontramos con el mismo problema que en el caso de las claves minimales respecto al valor de corte de la etapa de división \label{subseccion:BOV}. En la primera etapa del algoritmo paralelo hay que decidir cuándo detener la expansión de una rama del árbol de búsqueda y generar el subproblema actual correspondiente para que se resuelva en paralelo posteriormente. Para ello, vamos a utilizar el \textit{BOV}, que representa el cardinal del conjunto de implicaciones del nodo actual. El \textit{BOV} se calcula como un porcentaje del tamaño de la entrada y debe ser estimado para equilibrar el trabajo realizado por cada núcleo al actuar en paralelo.

Sin embargo, se nos presenta la misma problemática que en el caso de las claves minimales, es decir, si decidimos detenernos en un nivel cercano a la raíz del árbol seleccionando un \textit{BOV} bajo (es decir, un alto número de implicaciones), ciertamente estamos reduciendo el tiempo de ejecución de la etapa de división y sólo se crearían unos pocos subproblemas. En consecuencia, dado que el árbol no habría sido capaz de expandirse aún, no tendremos suficiente material para aprovechar la computación paralela usando diferentes núcleos. Por otro lado, si detenemos la división en un nivel lejos de la raíz, el proceso de división seguramente creará una gran cantidad de subproblemas que pueden sacar partido del paralelismo, pero el tiempo de ejecución de esta primera etapa seguramente crecerá. Esta tesitura es la que nos lleva a seleccionar un \textit{BOV} empíricamente, ya que es realmente difícil obtener el valor más óptimo con sólo analizar la entrada teóricamente. Sin embargo, después de hacer muchos experimentos, hay varios aspectos que vale la pena mencionar y esta sección se presenta con esa intención.

Para explorar las situaciones que se pueden dar cuando elegimos diferentes valores de \textit{BOV}, hemos repetido nuestros experimentos paralelos usando diversos \textit{BOV}. Tomamos \textit{BOV} tales que la etapa de división alcance una mayor profundidad en el árbol, en concreto, utilizaremos 130 y 100 como valores de \textit{BOV}, es decir, el $\approx86.67\%$ y $\approx66.67\%$ del conjunto original de implicaciones, respectivamente. Esta selección de valores no se hace por casualidad sino con el objetivo de provocar ciertas situaciones que hemos encontrado después de llevar a cabo una gran cantidad de experimentos que analizaremos a continuación. Los resultados relativos a los tiempos de ejecución son muestran en la Tabla \ref{table:differentsBOVs}.

\begin{table}[htbp]
\scriptsize
	\centering
\caption{Experimentos utilizando diferentes valores de \textit{BOV} con la implementación paralela \textit{MinGenPar} sobre problemas de gran tamaño.}
\label{table:differentsBOVs}
\begin{tabular}{lrrr>{}rr}
\noalign{\smallskip}\hline\noalign{\smallskip}
Problema & Subp & División$_{t}$(s) & Paralelo$_{t}$(s) & Total$_{t}$(s) & BOV\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-1 & 0 & 44 & - & 44 & 66.67\%\\
 & 0 & 41 & - & 41 & 86.67\%\\
 & 11 & 3 & 1 & \cellcolor{gray!25}4 & \cellcolor{gray!25}93.33\%\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-2 & 0 & 18.533 & - & 18.533 & 66.67\%\\
& 885 & 8.532 & 58 & 8.590 & 86.67\%\\
 & 347 & 220 & 55 & \cellcolor{gray!25}275 & \cellcolor{gray!25}93.33\%\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-3 & 0 & 33.377 & - & 33.377 & 66.67\%\\
 & 0 & 33.285 & - & 33.285 & 86.67\%\\
 & 822 & 2.338 & 251 & \cellcolor{gray!25}2.589 & \cellcolor{gray!25}93.33\%\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-4 & 0 & 4.858 & - & 4.858 & 66.67\%\\
 & 308 & 3.703 & 22 & 3.725 & 86.67\%\\
 & 344 & 350 & 97 & \cellcolor{gray!25}447 & \cellcolor{gray!25}93.33\%\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-5 & 0 & 1.601 & - & 1.601 & 66.67\%\\
 & 0 & 1.547 & - & 1.547 & 86.67\%\\
 & 168 & 432 & 30 & \cellcolor{gray!25}462 & \cellcolor{gray!25}93.33\%\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-6 & 0 & 772 & - & 772 & 66.67\%\\
 & 144 & 492 & 11 & 503 & 86.67\%\\
 & 79 & 35 & 7 & \cellcolor{gray!25}42 & \cellcolor{gray!25}93.33\%\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-7 & 0 & 167.451 & - & 167.451 & 66.67\%\\
 & 5.412 & 96.433 & 295 & 96.728 & 86.67\%\\
 & 1.754 & 958 & 242 & \cellcolor{gray!25}1.200 & \cellcolor{gray!25}93.33\%\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-8 & 0 & 75.060 & - & 75.060 & 66.67\%\\
 & 5.344 & 41.404 & 375 & 41.779 & 86.67\%\\
 & 966 & 253 & 188 & \cellcolor{gray!25}441 & \cellcolor{gray!25}93.33\%\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-9 & 0 & 82 & - & 82 & 66.67\%\\
 & 24 & 42 & 2 & 44 & 86.67\%\\
 & 24 & 7 & 2 & \cellcolor{gray!25}9 & \cellcolor{gray!25}93.33\%\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenPar-10 & 0 & 9.438 & - & 9.438 & 66.67\%\\
 & 697 & 6.569 & 50 & 6.619 & 86.67\%\\
 & 277 & 186 & 65 & \cellcolor{gray!25}251 & \cellcolor{gray!25}93.33\%\\
\noalign{\smallskip}\hline
\end{tabular}
\end{table}

A la luz de estos resultados, cabe destacar en primer lugar que, excepto para el problema MinGenPar-1 donde existe una diferencia sutil, todos los problemas se comportan peor con respecto al tiempo de ejecución cuando demoramos el punto de división. Para encontrar una explicación, ponemos nuestra atención en el número de
subproblemas, donde van a surgir cuatro comportamientos diferentes cuando variamos el \textit{BOV}. Procedemos a enumerar cada uno de ellos con el apoyo de los resultados obtenidos en la Tabla \ref{table:differentsBOVs}.

Sea $BOV_1$, $BOV_2$ dos $BOV$ diferentes para el mismo experimento tal que $BOV_1 > BOV_2$, y sea $Sp_1, Sp_2$ el número de subproblemas generados en cada ejecución, respectivamente. Entonces, pueden acontecer diferentes escenarios donde:

\begin{enumerate}
	\item $Sp_1 < Sp_2$. Esta puede ser la situación más natural ya que con $BOV_2 < BOV_1$ el algoritmo tiene más margen para expandir el árbol y generar más subproblemas. De esta forma, el paralelismo tomaría ventaja, pero al aumentar el tiempo necesario para dividir, el tiempo de ejecución global empeoraría. Los experimentos Problemas MinGenPar-\{2,6,7,8,10\} reflejan esta situación.
	\item $Sp_1 > Sp_2$. Puede suceder que incluso profundizando en el árbol obtengamos menos nodos, es decir, menos subproblemas. Esto se debe a que hay ramas que terminan antes de alcanzar los $BOV$ y se resuelven dentro de la etapa de división, por lo que el tiempo de ejecución aumenta. Podemos ver este caso en el problema MinGenPar-4.
	\item $Sp_1 \neq 0 \land Sp_2 = 0$. Siguiendo con el punto anterior, podemos caer en una situación extrema donde no se generan subproblemas dentro de la etapa de división porque cada rama del árbol termina antes del punto de división \textit{BOV}, por lo tanto el problema original se resuelve por completo dentro de la etapa de división sin alcanzar el escenario paralelo. Esta situación se puede considerar como el peor de los casos, ya que la implementación paralela funciona igual que la secuencial. Esto sucede para cada problema cuando se usa un $BOV \approx66.67\%$ y también en problemas como MinGenRd-\{1,3,5\} incluso con un $BOV \approx86.67\%$.
	\item $Sp_1 = Sp_2$. Finalmente, aunque utilicemos diferentes $BOV$, podemos obtener el mismo número de subproblemas. Esto refleja una intrincada situación en la que los niveles inferiores del árbol pueden contar con el mismo número de nodos que los superiores. La cuestión clave es que cuando profundicemos en el árbol, podemos generar más nodos a medida que el árbol se expande y así crecerá el número de subproblemas, pero también pueden ser varias las ramas que terminan antes de seguir profundizando, y por lo tanto reduce el número de nodos. Por lo tanto, con estas adiciones y sustracciones, el cálculo global de subproblemas puede terminar en un empate aunque se utilicen diferentes $BOV$ como se muestra en el problema MinGenRd-9. Pero eso no es todo. El Problema MinGenRd-9 muestra, efectivamente, el mismo número de subproblemas para $BOV \approx93.33\%$ y $BOV \approx86.67\%$, sin embargo, el tiempo de ejecución no es el mismo, de hecho, es peor para un $BOV \approx86.67\%$ ya que hemos prolongado la etapa de división. 
\end{enumerate}


\subsection{Estimación del número óptimo de cores}
\label{seccion:numeroCoresMinGen}
Hasta ahora, podemos pensar que es sólo una cuestión de recursos el poder tratar con problemas de mayor tamaño y aún así obtener resultados dentro de un tiempo razonable. Sin embargo, no es tan obvio y este apartado está dedicado a analizar este hecho. Con este propósito, los problemas de gran tamaño usados anteriormente en la sección \ref{seccion:algoritmoParalelo} se analizarán nuevamente usando: 16, 32, 48, 64 y 80 núcleos cada vez. Los resultados se muestran en la Tabla \ref{table:speedup}.

\begin{table}[htbp]
\scriptsize
	\centering
\caption{Tiempos de ejecución (en segundos) de los resultados obtenidos incrementando el número de cores para la ejecución en paralelo.}
\label{table:speedup}
\begin{tabular}{lrrrrr}
\noalign{\smallskip}\hline\noalign{\smallskip}
Problema & \multicolumn{5}{c}{Número de cores}\\
\noalign{\smallskip}\hline\noalign{\smallskip}
 & 16 & 32 & 48 & 64 & 80\\
\noalign{\smallskip}\hline\noalign{\smallskip}
MinGenRd-1 & 5 & 4 & \cellcolor{gray!25}3 & \cellcolor{gray!25}3 & \cellcolor{gray!25}3\\
MinGenRd-2 & 310 & 275 & 199 & \cellcolor{gray!25}190 & 197\\
MinGenRd-3 & 2.742 & 2.589 & 2.122 & 2.078 & \cellcolor{gray!25}2.075\\
MinGenRd-4 & 512 & 447 & 444 & \cellcolor{gray!25}440 & 446\\
MinGenRd-5 & 598 & 462 & \cellcolor{gray!25}416 & 445 & 442\\
MinGenRd-6 & 50 & 42 & \cellcolor{gray!25}34 & 35 & \cellcolor{gray!25}34\\
MinGenRd-7 & 1.457 & 1.200 & 1.078 & \cellcolor{gray!25}1.010 & 1.012\\
MinGenRd-8 & 499 & 441 & 432 & 430 & \cellcolor{gray!25}425\\
MinGenRd-9 & 9 & 9 & \cellcolor{gray!25}7 & \cellcolor{gray!25}7 & \cellcolor{gray!25}7\\
MinGenRd-10 & 267 & 251 & 196 & \cellcolor{gray!25}194 & 195\\
\noalign{\smallskip}\hline
\end{tabular}
\end{table}

Aunque los recursos son mejores ahora, los resultados no acompañan. Se puede ver que mejoramos el rendimiento mediante el uso de más núcleos (por ejemplo, de 16 a 64 núcleos), sin embargo, llega un momento donde no se obtiene mejora; los resultados son bastante similares para 48, 64 y 80 núcleos. Esto se debe al hecho de que hay varias ramas en el árbol (tal vez sólo una) que tarda mucho en terminar y por tanto, no importa cuánto mejoremos los recursos, el tiempo global sigue siendo casi el mismo. El problema es que por el momento, no podemos predecir si una rama resultará en una larga o corta. Esta situación detiene nuestras primeras intenciones de aumentar ciegamente la cantidad de recursos y muestra que, el número de núcleos para este problema se puede establecer en 64 como un valor óptimo, logrando un equilibrio entre los recursos necesarios y los beneficios obtenidos.


\subsection{Generadores minimales para un \textit{dataset} real}
\label{seccion:minGenMushroom}
Para nalizar adecuadamente esta sección, traemos ahora los resultados obtenidos al aplicar el algoritmo de cálculo de generadores minimales a un conjunto de datos del mundo real. En particular, hemos elegido \textit{Mushroom Data Set}\footnote{https://archive.ics.uci.edu/ml/datasets/mushroom} accesible desde el sitio web de la Universidad de California, Irvine (UCI)\footnote{http://archive.ics.uci.edu/ml/}. Básicamente, este conjunto de datos incluye descripciones de hipotéticas muestras correspondientes a 8.124 especies de setas utilizando 22 atributos diferentes.

En este conjunto de datos, se realiza una adaptación para convertir la información de entrada cuyo formato contempla múltiples valores, en información binaria de manera que pueda ser tratada por el algoritmo \ref{algoritmo:funcionMinGenPar}. Como resultado, obtenemos un \textit{dataset} con 126 atributos y un conjunto de implicaciones para este \textit{dataset} de 1.587. Queremos declarar que con tal número de implicaciones, la versión secuencial del algoritmo no termina. Para llevar a cabo este experimento usamos las conclusiones alcanzadas anteriormente, es decir, utilizaremos 64 núcleos diferentes y un $BOV \approx93.33\%$, es decir $BOV = 1.481$, ya que son ser los mejores valores para proceder.

Los resultados de este experimento se muestran en la tabla \ref{table:mushroom}, donde se aprecia claramente la forma en que nuestro algoritmo cumple con las expectativas cuando se trata de un conjunto de datos de gran tamaño y del mundo real.

\begin{table}[htbp]
\scriptsize
	\centering
\caption{Algoritmo \ref{algoritmo:funcionMinGenPar} aplicado sobre un \textit{dataset} real.}
\label{table:mushroom}
\begin{tabular}{lrrrrrr}
\hline\noalign{\smallskip}
 & Atrib & Implicaciones & BOV & Cores & \\
 & 126 & 1.587 & 1.481 & 64 &  \\
\noalign{\smallskip}\hline\noalign{\smallskip}
Problema \& Método  & Subp & División$_{t}$(s) & Paralelo$_{t}$(s) & Total$_{t}$(s) & Nodos & MinGens\\
\noalign{\smallskip}\hline\noalign{\smallskip}
%mushrooms-sequential & - & - & - & \cellcolor{gray!25}1.613 & 81.363 & 17.127\\
mushrooms-parallel & 224 & 152 & 9 & \cellcolor{gray!25}161 & 81.363 & 17.127\\
\noalign{\smallskip}\hline
\end{tabular}
\end{table}


% =====================================================================
% =====================================================================
% =====================================================================