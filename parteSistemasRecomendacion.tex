% this file is called up by thesis.tex
% content in this file will be fed into the main document

\pagestyle{empty}
%: ----------------------- name of chapter  -------------------------
\chapter{Sistemas de Recomendación}
\label{cap:sistemasRecomendacion} % top level followed by section, subsection

\pagestyle{headings}

\bigdrop{0pt}{5}{cmr10}En la actualidad, suele ser difícil encontrar un día en el que no hayamos participado en situaciones donde intervenga algún tipo de recomendación. En este sentido, la ciencia y la tecnología han colaborado en el desarrollo y expansión de los sistemas de recomendación (SR) y a establecer un claro campo de conocimiento dentro de la gestión de la información. 

Un SR es un sistema inteligente que proporciona a los usuarios una serie de sugerencias personalizadas (recomendaciones) sobre un determinado tipo de elementos (ítems). De forma general, los SR estudian las características de cada usuario e ítem, y mediante un procesamiento de los datos, encuentra un subconjunto de ítems que pueden resultar de interés para el usuario. Una de las referencias más notables en el campo de los SR la encontramos en el libro de Adomavicius y otros \cite{AdomaviciusBook11}.

% Historia
Desde que el primer SR hizo su aparición en el mundo de las tecnologías de la información \cite{Hill1995,Resnick1997}, los SR han estado en continua evolución durante los últimos años \cite{Adomavicius2005}. Sin embargo, es con la expansión de las nuevas tecnologías cuando han tenido un acercamiento más directo a la mayor parte de la sociedad debido a su capacidad para realizar todo tipo de recomendaciones sobre diversos elementos al alcance de todos (libros \cite{Crespo2011}, documentos \cite{Porcel2012}, música \cite{LampropoulosLT12}, turismo \cite{BorrasFPMVIORC11}, películas\footnote{https://www.movielens.org}, etc.). 

% Importancia
En la actualidad, los SR constituyen un claro campo de investigación y estudio como demuestran el gran número de trabajos que se están realizando \cite{Son2018,Eirinaki2018} y cuya cantidad continúa aumentando día a día. Además, la relevancia de estos sistemas no se limita al ámbito investigador. Actualmente, muchos SR ya han sido implantados con éxito en fuertes entornos comerciales a nivel mundial. Este es el caso de empresas líderes en el sector como pueden ser Amazon \cite{linden2003}, LinkedIn \cite{Metaphor2012} o Facebook \cite{Tiroshi11}, que han realizado fuertes inversiones con el fin de generar mejores SR. Estas situaciones ponen de manifiesto la gran importancia de estos sistemas en ambas vertientes de la sociedad actual.

Tras esta introducción al concepto SR y la importancia que abarca en los sistemas actuales, durante el resto de este capítulo vamos a ahondar en las características que intervienen en este tipo de sistemas. En este sentido, nuestra intención es doble; por un lado conseguimos aumentar la naturaleza autocontenida de la tesis, y por otro introducimos una serie de conceptos que serán claves para razonar los capítulos posteriores. En concreto, en primer lugar, se presenta una breve clasificación de las diferentes técnicas de recomendación que existen y la justificación de la elegida para el desarrollo de un SR en nuestro caso particular \ref{seccion:tecnicasRecomendacion}. A continuación, se presenta una serie de problemas de los que suelen adolecer este tipo de sistemas \ref{seccion:problemasRecomendacion}. Finalmente, la última parte está dedicada a presentar las medidas que se utilizan para evaluar el rendimiento de estos sistemas \ref{seccion:evaluacionSistemasRecomendacion}.


\section{Técnicas de recomendación}
\label{seccion:tecnicasRecomendacion}
% Tipos
Existen numerosos tipos diferentes de SR que normalmente se clasifican atendiendo a cómo se llevan a cabo las recomendaciones. Los más conocidos y extendidos son los sistemas de filtrado colaborativo (denominados CF, por sus siglas en inglés: \textit{Collaborative Filtering}) y los sistemas basados en contenido (denominados CB, por sus siglas en inglés: \textit{Content-Based}). Los primeros SR de filtrado colaborativo apuntan a GroupLens \cite{Konstan1997} o Video Recommender \cite{Hill1995}. Este tipo de SR basa su funcionamiento fundamentalmente en las valoraciones que otros usuarios han otorgado a los elementos disponibles, y en realidad, la mayoría de los SR actuales utilizan técnicas de filtrado colaborativo en algún aspecto. Por su parte, los SR basados en contenido se basan en categorizar los ítems a recomendar, proporcionando resultados que tengan características similares a otros que han sido bien valorados anteriormente por el usuario. La mención de los SR basados en contenido es esencial por dos motivos; en primer lugar, es un tipo de SR que ha alcanzado una gran importancia en la actualidad debido a la tremenda expansión de las redes sociales, donde los usuarios introducen multitud de información de forma masiva, y en segundo lugar, aportará características al sistema desarrollado en esta tesis. 

Además, en los últimos años ha habido un gran crecimiento de los SR contextuales \cite{BenSassi2017}, capaces de tener en cuenta información relevante para la recomendación como puede ser la hora, el lugar, la compañía, la ubicación, etc. Existe otro grupo denominado SR demográficos \cite{BeelLNG13} que clasifican a los usuarios según diferentes parámetros personales (edad, localización, etc.) y realizan las recomendaciones teniendo en cuenta el grupo demográfico al que pertenece el usuario. Estos sistemas no requieren información histórica, sin embargo, requieren información que pueda ser sensible para la privacidad del usuario. 

Por otro lado encontramos un tipo de recomendador de vital importancia para el trabajo de esta tesis, son los denominados SR basados en conocimiento (KB, por sus siglas en inglés: \textit{Knowledge-Based}) \cite{Mandl2011}. Estos sistemas gestionan el conocimiento inherente a los datos y revelan cómo un ítem puede satisfacer la necesidad del usuario, es decir, utilizan un método de razonamiento para inferir la relación entre una necesidad y una posible recomendación. 

Llegamos ahora a los SR más importantes desde el punto de vista de este trabajo, los denominados SR conversacionales \cite{Griol2018,Lee2017}. Estos están estrechamente relacionados con los conceptos de recomendador basado en críticas \cite{Chen2012} y recomendaciones de información \cite{TrabelsiWBR11}.

En estos sistemas, se aplica un proceso iterativo en el cual el usuario selecciona una o más características que desea que los ítems verifiquen. Esta forma de proceder a través de la interacción con el usuario, contrasta con la tendencia histórica de los SR de dar una recomendación con sólo una consulta. A partir de esta interacción y usando diferentes técnicas, el sistema progresa eligiendo (o incluso prediciendo) elementos que concuerdan con las preferencias del usuario. La ventaja principal de este tipo de SR es que a partir de las respuestas del usuario, el sistema es capaz de refinar la recomendación en cada ronda sucesiva del diálogo. Resaltamos este tipo de SR porque será la estrategia principal sobre el que se sustenta el desarrollo de SR realizado y que ha dado lugar a una de las contribuciones que avalan esta tesis \cite{Benito-Picazo2017}. 

Es posible estudiar más estrategias de recomendación; para ello, podemos encontrar una recopilación más detallada, junto con las principales tendencias, en dos de las referencias más importantes de este campo de conocimiento \cite{Adomavicius2005,Bobadilla2013}.

En párrafos anteriores hemos podido apreciar que existen diferentes tipos de estrategias para los SR, sin embargo, la historia ha demostrado ampliamente que la mejor alternativa consiste en combinar características de diferentes tipos de SR para generar híbridos que se beneficien de las ventajas de cada uno de ellos \cite{DeCampos2010}. Ésta ha sido exactamente nuestra intención principal, la cual, una vez introducidos los diferentes tipos de recomendadores, ya estamos en condiciones de establecer.

\vspace{0.3cm}

Nuestro trabajo ha culminado en un SR híbrido que combina las siguientes técnicas de recomendación:
\begin{itemize}
	\item \textbf{SR basados en conocimiento.} En virtud de nuestro estudio de extracción de conocimiento de los datos utilizando FCA, los conjuntos de implicaciones y los operadores de cierre.
	\item \textbf{SR basados en contenido.} Necesario ya que para aplicar las técnicas lógicas empleadas necesitamos en primera instancia información sobre la que trabajar. 
	\item \textbf{SR conversacionales.} Se presenta como estrategia central sobre la que aplicar y utilizar las dos anteriores respectivamente.
\end{itemize}

Como veremos a continuación, esta combinación de estrategias nos va a permitir abordar el denominado problema de la dimensionalidad que podemos encontrar frecuentemente al trabajar con SR.


\section{Problemas comunes}
\label{seccion:problemasRecomendacion}
% Problemas
Si bien es cierto el éxito que están alcanzando los SR, también tenemos que añadir que estos sistemas no están exentos de problemas y dificultades. En esta sección vamos a hacer una breve recopilación de aquellos que tienen una mayor presencia e importancia. Tal es el caso de uno de los problemas más comunes, el denominado arranque en frío o \textit{cold-start} \cite{Feil2016}, que aparece cuando un nuevo usuario o ítem se incluye en el sistema. Estos nuevos elementos carecen de información propia y por tanto no es posible hacer predicciones sobre ellos. Un estudio muy completo al respecto de las soluciones propuestas a este problema puede verse en \cite{Son201687}. 

En otros casos, el problema del SR llega de la mano de la escasez de datos \cite{Guo2012}, ya que no siempre se posee la cantidad de información deseable para los ítems del sistema. Otros problemas pueden venir de la mano de la suplantación de la identidad (en inglés \textit{Shilling attacks}). En estos problemas o ataques, el usuario puede hacer un uso malicioso del sistema para obtener beneficio propio. Es un problema muy difícil de detectar \cite{Yang2016} o impedir, sin embargo, cada vez se desarrollan más técnicas para hacerle frente y es un gran campo de investigación dentro de los SR \cite{Zhang2013,Zhou2015}.

Además, existen muchos otros problemas como son: privacidad \cite{Friedman2015}, oveja girs/negra o \textit{black-sheep} \cite{Gras2016}, sobreespecialización \cite{LopsGS11}, escalabilidad \cite{Isinkaye2015}, postergación (en inglés, \textit{long-tail items}) \cite{Sundaresan2011}, dimensionalidad \cite{Salimi2017}, etc.

En concreto, nuestro trabajo ha estado orientado a resolver este último problema, la dimensionalidad cuando estamos trabajando sobre SR. Este problema, también conocido como \textit{the curse of dimensionality phenomenon} \cite{Salimi2017,Nagler2016} aparece cuando es necesario trabajar sobre datasets con un alto número de características (variables o atributos). De forma intuitiva, podríamos introducirlo de la siguiente manera. Cuando hay pocas columnas de datos, es relativamente fácil para los algoritmos realizar tareas de tratamiento inteligente de la información como: aprendizaje automático, \textit{clustering}, clasificación, etc. Sin embargo, a medida que aumentan las columnas o características de nuestros ítems, se vuelve exponencialmente más difícil hacer labores predictivas con un buen nivel de precisión. El número de filas de datos necesarias para realizar cualquier modelado útil aumenta exponencialmente a medida que agregamos más columnas a una tabla.

La maldición de la dimensión representa un obstáculo importante a la hora de resolver problemas de gestión de la información que se plantean en el contexto del aprendizaje automático. Como ejemplo concreto encontramos el algoritmo de los k-vecinos, muy utilizado en SR \cite{Shirude2016}, en el cual al aumentar la dimensión, la distancia al vecino más próximo crece.

Este problema también se hace latente en el campo de los SR al administrar grandes volúmenes de información sobre los que poder realizar recomendaciones al usuario teniendo en cuenta que el número de alternativas es muy elevado. Para abordar este problema, podemos encontrar muchos trabajos en la literatura sobre la reducción de la dimensión de la información, especialmente mediante selección de características \textit{(feature selection)}, que pueden ayudarnos a descartar aquellas características que no son merecedoras de ser considerados según diferentes criterios. De hecho, estas técnicas ya se aplican en otras áreas como son: algoritmos genéticos o redes neuronales, normalmente centrándose en la aplicación de un proceso automatizado que se aplique de una vez \textit{(batch mode)} mediante selección de características.

Suele ser habitual que para realizar una selección de características por parte del SR, el usuario tenga que introducir y seleccionar información del sistema una y otra vez. Esto constituye un problema dado que pueden existir artículos para los cuales el número de características que los definen sea muy elevado y en consecuencia, incomode la correcta interacción del usuario con el sistema, poniendo de manifiesto de nuevo cómo la alta dimensionalidad constituye un problema para los SR.

En definitiva, nuestro objetivo es abordar el problema de la alta dimensionalidad en los SR a través de un proceso de selección de atributos por parte del usuario mediante un SR conversacional que utilice características de los SR basados en contenido y en conocimiento.

Un trabajo interesante en esta área es \cite{Jannach2009}, que establece la idoneidad de los enfoques basados en el conocimiento para los procesos conversacionales.
En particular, estos autores utilizan el razonamiento basado en restricciones, en lugar de nuestro enfoque basado en la lógica. Además, este trabajo trata sobre
concepto de optimización de consultas, análogo al aplicado en nuestra propuesta. Otro trabajo notable es \cite{TrabelsiWBR11}, que comparte nuestro objetivo de disminuir el número de pasos de la conversación. Los autores proponen métricas acerca del número de pasos de la conversación y tasas de poda, ambos muy similares a los utilizados en nuestro trabajo como veremos más adelante. Por otro lado, en \cite{Chen2007}, los autores demuestran cómo la posibilidad de que sea el usuario el encargado de la selección de atributos supera al hecho de que sea el sistema mismo el encargado de dicha selección. Este hecho respalda nuestro enfoque en el cual el humano experto guía la conversación y el proceso de selección de características.


\section{Evaluación de los sistemas de recomendación}
\label{seccion:evaluacionSistemasRecomendacion}
Desde que se inició la investigación de los SR, la evaluación de las predicciones y recomendaciones se ha convertido en un aspecto muy importante \cite{Herlocker2004,Burke2010}. Los SR requieren medidas de calidad y métricas de evaluación \cite{Gunawardana2009} para conocer la calidad de las técnicas, métodos y algoritmos para las predicciones y recomendaciones. Las métricas de evaluación \cite{HernandezdelOlmo2008} y los \textit{frameworks} de evaluación \cite{Bobadilla2011} facilitan la comparación de varias soluciones para el mismo problema. 

No obstante, teniendo en cuenta la gran variedad de factores que pueden intervenir en el funcionamiento de los SR, la primera tarea a llevar a cabo es analizar qué tipo de métrica es la que mejor se adapta al SR que queremos evaluar. Con el fin de medir la calidad de los resultados de las recomendaciones de un SR, es habitual utilizar el cálculo de algunas de las métricas de predicción de errores más comunes. El uso de estas métricas nos da una forma de comprobar la eficacia de SR calculando una medida del error en las predicciones. Entre estas métricas destacan el error absoluto medio (MAE) y sus métricas relacionadas: error cuadrático medio, raíz del error cuadrático medio (RMSE), el error medio absoluto normalizado (NMAE) \cite{Zhang2016}.

También son muy comunes aquellas métricas aplicadas a la precisión en las clasificaciones \cite{Avazpour2014}. Dado que gran parte de los SR basa su funcionamiento en el concepto de valoración, la aplicación de estas medidas para evaluar la precisión del recomendador es una tarea prácticamente imprescindible es gran cantidad de SR. Las métricas más destacadas en este grupo son Precisión, Memoria y F1 \cite{Shani2011}.

Además de las métricas mencionadas, existen otras tantas que también pueden ser de aplicación como el coeficiente de correlación de Pearson, (en inglés \textit{Pearson Correlation Coefficient}, PCC), coeficiente de correlación de Spearman, estabilidad, fiabilidad, originalidad, diversidad, ...

No obstante, hay que tener en cuenta que dependiendo del SR con el que estemos trabajando, la evaluación habrá que llevarla a cabo utilizando aquellas métricas, que por su naturaleza y significado, tengan cabida en relación al SR que se desea evaluar. En este sentido, en el capítulo siguiente \ref{seccion:medidasEvaluacion} aplicaremos una serie de métricas relacionadas con los SR conversacionales para evaluar el rendimiento del SR desarrollado y justificaremos el porqué otras métricas tales como algunas de las introducidas en esta sección, no son susceptibles de aplicación en nuestro marco concreto de trabajo.  



\chapter{Desarrollo de SR conversacional}
\label{cap:desarrolloSR}

\pagestyle{headings}

\bigdrop{0pt}{5}{cmr10}Este capítulo va a estar dedicado a mostrar el proceso, las mejoras conseguidas y los principales resultados que han acompañado a la consecución del SR desarrollado y que ha sido la parte fundamental de uno de los trabajos publicados que sustentan esta tesis \cite{Benito-Picazo2017}. Es por tanto intención principal de este capítulo el mostrar cómo se ha utilizado la base teórica adquirida para culminar en una aplicación de ingeniería, y en definitiva, para transmitir el conocimiento a las aplicaciones. 

El texto va a estar repartido en tres secciones. La primera \ref{seccion:presentacionSR} y la segunda \ref{seccion:funcionamiento} están dedicadas a presentar el SR desarrollado y su funcionamiento respectivamente, mientras que en la última \ref{seccion:medidasEvaluacion} presentaremos las medidas de evaluación utilizadas para el caso concreto del sistema desarrollado.

\section{Presentación: \rs}
\label{seccion:presentacionSR}
Si bien cronológicamente el último paso del desarrollo fue establecer un nombre para nuestro SR, por comodidad para con el texto, esta vez vamos a proceder al contrario; presentamos en primera instancia a \rse como el SR creado a partir del trabajo de esta parte de la tesis. 

Como hemos mencionado con anterioridad, \rse va a ser un SR híbrido que va a combinar las estrategias de los SR conversacionales, basados en conocimiento y basados en contenido. Su finalidad va a ser abordar el problema de la dimensionalidad por medio un tratamiento eficiente de la información haciendo uso de FCA, las implicaciones y los operadores de cierre. En concreto haremos uso de la \slfde y del algoritmo del cierre \ref{algoritmo:Cls}.

Antes de entrar en el funcionamiento de \rs, hay que tener en cuenta que lo primero que vamos a necesitar son \textit{datasets} con elementos sobre el que poder hacer recomendaciones. Es necesario que estos \textit{datasets} contengan la información según una representación binaria, es decir, el valor de cada uno de los atributos asociados a cada elemento del sistema será un valor binario que representará si ese elemento verifica ese atributo o no lo hace. Para entender este aspecto, veamos el siguiente ejemplo.

\begin{ejemplo}
\label{ejemplo:coches}
Supongamos el \textit{dataset} \textit{Auto MPG Data Set}\footnote{http://archive.ics.uci.edu/ml/datasets/Auto+MPG} accesible desde la página web de la Universidad de California, Irvine (UCI)\footnote{http://archive.ics.uci.edu/ml/} que básicamente contiene características del motor de un vehículo con la intención de predecir el consumo (las siglas MPG proceden del inglés \textit{Miles Per Gallon}, o millas por galón.). Sobre este \textit{dataset} se hace la adaptación necesaria para convertir la información multivaluada en información binaria, de forma que se establecieron unos umbrales que asignaban a cada característica del \textit{dataset} un valor de 1 si superaba el umbral, 0 en otro caso. De esta forma \rse ya puede utilizar este \textit{dataset} modificado. La Tabla \ref{tabla:autoMPG} muestra un extracto de la información original utilizada y su correspondiente adaptación. 

\begin{table*}[htbp]
\caption{Extracto del \textit{dataset} Auto MPG Data Set de la UCI}
\label{tabla:autoMPG}
\centering
{\scriptsize
\begin{tabular}{lccccc}
\hline
Nombre & MPG &	Cilindrada &	Potencia &	Peso &	Aceleración\\
\hline
Chevrolet Monte Carlo & 15.0 &  8   & 150.0 & 3761 &  9.5\\
Buick Estate Wagon & 14.0 & 8  & 225.0 & 3086 & 10.0\\
Toyota Corolla Mark II & 24.0 &  4  & 95.00 &  2372 & 15.0\\
Plymouth Duster & 22.0 & 6  & 95.00 & 2833 & 15.5\\
\ldots\\
\hline
Chevrolet Monte Carlo & 1 & 1  & 0 & 1 & 0\\
Buick Estate Wagon & 1 & 1  & 0 & 1 & 0\\
Toyota Corolla Mark II & 0 & 0  & 1 & 0 & 1\\
Plymouth Duster & 0 & 1 & 1 & 0 & 1\\
\ldots\\
\hline
\end{tabular}
}
\end{table*}
\end{ejemplo}

Una vez tengamos los \textit{datasets} sobre los que vamos a trabajar, \rse necesita conocer las relaciones que hay entre sus atributos por medio de implicaciones lógicas, pero para ello existen aplicaciones capaces de extraer el conjunto de implicaciones que se verifican en un determinado \textit{dataset} \cite{HuhtalaKPT99,YaoHB2002,Yevtushenko2006}.


\section{Funcionamiento}
\label{seccion:funcionamiento}
Una vez presentado \rse y la información de entrada que debe tener para funcionar, pasamos ahora a explicar el proceso conversacional junto con un esquemas conceptuales que faciliten su comprensión.

Fundamentalmente, la naturaleza de sistema conversacional que se manifiesta en \rse nos lleva a que el proceso se desarrolle según una serie de etapas que pasamos a enumerar:

\begin{enumerate}
	\item La interacción del usuario con el sistema comienza cuando el usuario elige un atributo con el que realizar la búsqueda. En principio, \rse limita la elección de atributos a uno en cada paso de la conversación. De esta forma, podemos apreciar más fácilmente cómo funciona el sistema. No obstante, pruebas más avanzadas en las que hemos permitido la elección de múltiples atributos por cada paso han demostrado que el sistema mantiene su correcto funcionamiento e incluso aumenta más rápidamente la poda de información superflua.
	\item Una vez seleccionado el atributo, el proceso entra en el algoritmo \cierree para calcular el cierre del conjunto de atributos y al mismo tiempo, el conjunto de implicaciones que quedan fuera del cierre. 
	\item Una vez el \cierree termina, se muestra una primera recomendación. Esta recomendación es una lista de resultados con los elementos del \textit{dataset} que verifican el atributo seleccionado. Para conseguir esta lista el sistema realiza una consulta a base de datos solicitando aquellos elementos que verifiquen el atributo.
	\item En este punto, el usuario puede terminar el diálogo en caso de que ya esté satisfecho con el resultado o bien, puede continuar interactuando con el sistema por medio de la elección de un nuevo atributo. La ganancia en este momento se produce de la siguiente manera. 
	
	Para los sucesivos pasos del diálogo, hemos reducido el número de atributos disponibles eliminando aquellos que estén incluidos en el cierre debido a que son implícitos con respecto a la selección realizada. Como consecuencia, esos atributos implícitos no aparecerán en las sucesivas interacciones con el usuario, liberándolo así de tener que tratar con información redundante, lo cual actúa en beneficio directo a aliviar el problema de la alta dimensionalidad de la información. 
	
	No obstante, si bien es cierto que esta mejora puede alcanzarse con el algoritmo clásico del cierre \cite{Maier1983}, la mayor ventaja de usar el \cierree es que \textit{simultáneamente} estamos reduciendo el número de implicaciones, y por tanto, en cada nuevo paso del diálogo no necesitamos volver a extraer el nuevo conjunto de implicaciones, lo cual es una tarea de \textit{data-mining} con coste exponencial, sino que podemos continuar la interacción a partir aquí, donde tanto atributos como implicaciones han sido reducidas, y por tanto con coste \textit{lineal}.
	\item Finalmente, el usuario puede decidir si queda satisfecho con la recomendación obtenida, o bien si quedan más atributos disponibles para elegir, puede volver al paso 1 para continuar el diálogo y refinar la recomendación; en caso contrario el diálogo termina por no quedar más atributos que seleccionar.
\end{enumerate}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[height=.7\textheight,width=.8\textwidth]{diagramaSecuenciasicumaRS.png}
	\end{center}
	\caption{Diagrama de secuencia del funcionamiento de \rs.}
	\label{figura:diagramaSecuenciasicumaRS}
\end{figure}

Las Figuras \ref{figura:esquemaConversacional} y \ref{figura:diagramaSecuenciasicumaRS} nos ayudan a entender con mayor facilidad la sucesión de pasos que da el sistema conversacional para interactuar con el usuario y proponer recomendaciones. La primera representa el diagrama de secuencia del proceso en el cual intervienen el usuario (Alicia), el SR (en este caso \rs) y el sistema gestor de bases de datos (SGBD). Por otro lado, la Figura \ref{figura:esquemaConversacional} nos muestra un esquema conceptual aplicado a un caso determinado de la investigación realizada. En concreto, ese esquema representa el funcionamiento de \rse sobre un \textit{dataset} que agrupa información sobre anomalías hematológicas y fenotipos. Por tanto en el esquema podemos ver como se desarrolla un hipotético diálogo hasta alcanzar una lista de anomalías aceptable. Esta figura tiene una importancia mayor añadida ya que además de servir para ilustrar el funcionamiento del SR, muestra la ganancia que obtenemos al utilizar el \cierree frente a implementaciones clásicas. Los resultados de aplicación sobre este \textit{dataset} concreto pueden verse con mayor detalle en \cite{Benito-Picazo2017}.
 
\begin{figure}[htbp]
	\begin{center}
		\includegraphics[height=.5\textheight,width=.95\textwidth]{esquemaConversacional.png}
	\end{center}
	\caption{Diálogo entre el usuario y \rse que muestra el funcionamiento del sistema y la ganancia obtenida por el algoritmo \cierree frente al algoritmo clásico del cierre. Fuente \cite{Benito-Picazo2017}.}
	\label{figura:esquemaConversacional}
\end{figure}

Finalmente, vamos a terminar este apartado mostrando un ejemplo de aplicación del SR conversacional utilizando el \textit{dataset} de restaurantes que muestran los autores en \cite{LeivaERCMG13}. 

Este \textit{dataset} va a contar con 6 tipos diferentes de establecimientos que se relacionan con 11 facilidades que pueden ofrecer. La Tabla \ref{tabla:restaurants} muestra un extracto del aspecto del \textit{dataset}.

\begin{table*}[htbp]
\caption{\textit{Dataset} de restaurantes (extracto)}
\label{tabla:restaurants} 
\centering
{\scriptsize
\begin{tabular}{lccccccc}
\hline
Tipo de local & Abierto & Cerrado & Tranquilo & Animado & Pintoresco & Barato\\
\hline
Restaurante común & \checkmark & \checkmark & & \checkmark &  \\
%\hline
Estrella Michelín & & \checkmark & \checkmark & &  &  \\
%\hline
Burger &  & \checkmark &  & \checkmark &  & \checkmark  \\
%\hline
Bar Tapas &  & \checkmark &  & \checkmark & \checkmark & \checkmark  \\
%\hline
Pizzería &  & \checkmark &  & \checkmark &  & \checkmark  \\
%\hline
Chiringuito Playa & \checkmark &  &  & \checkmark & \checkmark &  \\
\hline
\end{tabular}
}
\end{table*}

Como consecuencia, vamos a tener un conjunto de atributos \textit{U = \{Abierto, Cerrado, Tranquilo, Animado, Pintoresco, Barato, Moderado, Caro, Aire Acondicionado (AC), Vistas, Terraza\}}. Además, una vez que hayamos utilizado alguna de las técnicas existentes para extraer las implicaciones que se verifican en la Tabla \ref{tabla:restaurants} obtenemos el siguiente conjunto de implicaciones:

%$\Gamma$ = \{$Terraza \rightarrow Animado;$ $Vistas \rightarrow Abierto, Animado, Pintoresco, Moderado, Terraza;$ $AC \rightarrow Cerrado;$ $Caro \rightarrow Cerrado, Tranquilo, AC;$ $Moderado \rightarrow Pintoresco;$ $Barato \rightarrow Cerrado, Animado;$ $Animado, Pintoresco, Terraza \rightarrow Abierto, Moderado, Vistas;$ $Animado, Pintoresco, Moderado \rightarrow Abierto, Vistas, Terraza;$ $Tranquilo \rightarrow Cerrado, AC;$ $Cerrado, Pintoresco, AC \rightarrow Tranquilo, Moderado;$ $Cerrado, Pintoresco, Moderado \rightarrow Tranquilo, AC;$ $Cerrado, Animado \rightarrow Barato;$ $Cerrado, Animado, Barato, Terraza \rightarrow AC;$ $Cerrado, Animado, Barato, AC \rightarrow Terraza;$ $Abierto \rightarrow Animado, Pintoresco, Moderado, Vistas, Terraza$\}.

\begin{itemize}
	\item $Terraza \rightarrow Animado;$
	\item $Vistas \rightarrow Abierto, Animado, Pintoresco, Moderado, Terraza;$
	\item $AC \rightarrow Cerrado;$
	\item $Caro \rightarrow Cerrado, Tranquilo, AC;$
	\item $Moderado \rightarrow Pintoresco;$
	\item $Barato \rightarrow Cerrado, Animado;$
	\item $Animado, Pintoresco, Terraza \rightarrow Abierto, Moderado, Vistas;$
	\item $Animado, Pintoresco, Moderado \rightarrow Abierto, Vistas, Terraza;$
	\item $Tranquilo \rightarrow Cerrado, AC;$
	\item $Cerrado, Pintoresco, AC \rightarrow Tranquilo, Moderado;$
	\item $Cerrado, Pintoresco, Moderado \rightarrow Tranquilo, AC;$
	\item $Cerrado, Animado \rightarrow Barato;$
	\item $Cerrado, Animado, Barato, Terraza \rightarrow AC;$
	\item $Cerrado, Animado, Barato, AC \rightarrow Terraza;$
	\item $Abierto \rightarrow Animado, Pintoresco, Moderado, Vistas, Terraza;$
\end{itemize}

En definitiva, el SR conversacional va a contar con unos datos de partida formados por: un conjunto de 6 restaurantes, 11 posibles atributos y 15 implicaciones que se verifican en los datos. Por tanto, pasemos ahora a realizar una simulación de posible diálogo.

\begin{ejemplo}
\label{ejemplo:restaurantes}
Supongamos que un usuario busca una recomendación sobre un restaurante para cenar. En primer lugar, busca que el lugar cuente con un atmósfera animada. Además, debido al buen clima reinante esta noche, es preferible que el establecimiento cuente con terraza. Para terminar, un precio moderado pondría la guinda al pastel.

De esta forma, el usuario comienza la interacción con el sistema introduciendo sus preferencias: \emph{Animado}, \emph{Terraza} y \emph{Moderado} de forma sucesiva y los resultados que se obtienen los podemos ver desglosados en la Tabla \ref{tabla:ejemploRestaurantes}. 

\begin{table*}[htbp]
\caption{Desglose paso a paso del diálogo entre el usuario y \rs.}
\label{tabla:ejemploRestaurantes} 
\centering
{\scriptsize
\begin{tabular}{rlllrl}
%\hline
%\multicolumn{2}{c}{Restaurants} & No. Attributes: 11 & No. Implications: 15 & No. Associations: 17 & Product T-Norm & Threshold: 0.9\\
%\hline
\hline
Iter. & Selección & Cierre & Atributos & Implics. & Resultados\\
% &       &           &         & Attributes & Implications & \\
\hline
1 & Animado & \{Animado\} & \{CS, Pintoresco,& 14 & \{Burguer,\\
  &  &  & Barato, OS,& & Pizzería,\\
  &  &  & Tranquilo, Moderado, & & Tapas,\\
  &  &  & Caro, AC, & & Playa\}\\
  &  &  & Vistas, Terraza\} & \\
%\hline
2 & Terraza & \{Animado, Terraza\} & \{CS, Pintoresco,& 13 & \{Pizzería,\\
  &  &  &  Barato, OS,& & Playa\}\\
  &  &  &  Tranquilo, Moderado,& & \\
  &  &  &  Caro, AC,& & \\
  &  &  &  Vistas\} & \\ 
3 & Moderado & \{Animado, Terraza, & \{CS, Barato, & 7 & \cellcolor{gray!25}\{Playa\}\\
  &  & Moderado, OS, & Tranquilo, Caro, & \\
  &  & Pintoresco, Vistas\} & AC\} & \\
\hline
\end{tabular}
}
\end{table*}
\end{ejemplo}

De este ejemplo podemos extraer algunas conclusiones interesantes que recogemos en la lista siguiente:
\begin{itemize}
	\item Primero y más importante; hemos conseguido que la interacción con el usuario sea más sencilla ya que no hay necesidad de tener que tratar con todos los atributos posibles a cada paso de la conversación. En cada momento, el sistema ha ido eliminando aquellos atributos que por la selección de otros se encuentran implícitamente incluidos. Gracias a ello, el diálogo entre el usuario y el sistema se hace más dinámico por dos razones: 
	\begin{enumerate}
		\item Se evita que los usuarios tengan que navegar entre atributos redundantes.
		\item La lista de atributos disponible depende de las elecciones previas, por tanto, los resultados pueden diferir entre un acceso al sistema y otro, evitando de esta forma obtener siempre los mismos resultados una y otra vez.
	\end{enumerate}  
	\item Gracias al algoritmo \cierre, conseguimos que en cada paso de la conversación, una vez aplicado, se reduzcan tanto el número de atributos disponible como el número de implicaciones, lo que redunda en una reducción de los tiempos de respuesta del sistema.
	\item También hemos de comentar que puede ocurrir que el usuario obtenga una recomendación satisfactoria antes de que la lista de resultados tenga una longitud manejable. En estos casos, el diálogo entre el usuario y el sistema puede acabar con una lista de posibles alternativas todavía muy extensa, pero en cualquier caso el sistema habrá guiado de forma eficiente al usuario hasta este punto. De hecho, en caso de no estar del todo satisfecho todavía, la solución pasa por continuar eligiendo atributos hasta que la lista de resultados sea más tratable, pero en cualquier caso, el sistema depende de la iniciativa del usuario.
\end{itemize}






\section{Medidas de evaluación}
\label{seccion:medidasEvaluacion}
Como es razonable, todo sistema debe someterse a una serie de evaluaciones que confirmen su viabilidad y su utilidad. Con \rse hemos realizado este tipo de evaluaciones y para ello vamos a pasar a definir qué medidas se han utilizado para llevar a cabo esta evaluación.

Recordemos que en apartados sucesivos se analizaron muchas de las diferentes métricas de evaluación de los SR que existen en la literatura. Sin embargo, no todas son adecuadas para todos los SR; dependiendo del SR habrá unas que sean razonables de aplicar y otras que no tengan cabida. En nuestro caso, dado que estamos tratando con un SR conversacional, puede ser evidente que la primera medida que podemos aplicar es calcular el número de pasos que se producen en la conversación \cite{McSherry01} como hemos estado viendo en los ejemplos anteriores. Por contra, otras métricas tan populares como son \textit{Precision} y \textit{Recall} \cite{Gunawardana2015} no son adecuadas de aplicar en nuestro caso porque obtendríamos siempre valores máximos en ambas métricas y la razón es la siguiente:
\begin{itemize}
	\item En primer lugar, cualquier ítem de la lista de resultados, verifica los atributos seleccionados ya que la consulta que se lanza a la base de datos para obtener la lista de ítems contiene esas restricciones.
	\item Y en segundo lugar, a cada paso del diálogo, el sistema devuelve todos los ítems que verifiquen la selección de atributos establecida por el usuario.
\end{itemize}
 
Sucede una situación similar cuando estamos hablando de otras métricas muy utilizadas como son MAE o RMSE. Estas métricas basadas en valoraciones no tienen cabida en nuestro sistema puesto que no existen valoraciones con la que el sistema trabaje. 

Asimismo, no existe la necesidad de de considerar métricas referentes a la exactitud de los resultados ya que \rse no es un modelo de predicción, su funcionamiento está basado en implicaciones y eso nos asegura un 100\% de exactitud en las respuestas. 

Afortunadamente, existen otras medidas que pueden reflejar los resultados de los experimentos. Las explicamos a continuación:

\subsubsection*{Número de pasos ($N$)}
\noindent
Como su nombre indica, esta métrica registra el número de pasos que se dan en el diálogo y en consecuencia, el número de atributos seleccionados por el usuario. Nos proporciona una visión clara de si el sistema ha necesitado mucha o poca interacción para satisfacer la demanda del usuario. Hay que aclarar, sin pérdida de generalidad, que en los experimentos realizados, dependiendo del \textit{dataset} sobre el que trabajemos, se ha establecido un tamaño máximo de la lista de resultados como indicador de aceptación por parte del usuario; por ejemplo, se establece que el usuario se considera satisfecho cuando una recomendación de hoteles contenga como máximo 10 hoteles. 

\[ N = |\text{Atributos seleccionados}|, \quad \text{donde $|A|$ representa el cardinal de A.}\]

\subsubsection*{Velocidad de poda en cada paso i ($S_i$)}
\noindent
Esta métrica evalúa el porcentaje de atributos que el sistema libera al usuario de tener en cuenta a lo largo de la conversación y de forma acumulativa de un paso al siguiente. Con esta métrica buscamos averiguar si los ratios de poda del algoritmo son mejores al principio de la conversación o en los pasos posteriores. Es una métrica para medir cuán rápido es el sistema reduciendo la sobrecarga de información.

\[ S_{i} = \frac{|\text{Atributos del cierre}|_{i} - i}{|\text{M}|}\] 
Siendo $i = 1,...,N$, y $M$ el conjunto global de atributos.


\subsubsection*{Reducción de atributos ($P$)}
\noindent
Esta última métrica nos informa de la reducción global de atributos que ha realizado el sistema al terminar el diálogo. La reducción de estos atributos es consistente ya que es fruto de la aplicación del algoritmo del cierre a partir de las selecciones realizadas por el usuario. Formalmente:
\[ P = S_N \]

%Con la presentación de las métricas de evaluación, tenemos ya todo lo necesario para poder realizar experimentos. No obstante, puesto que los experimentos van a llevarse a cabo sobre \textit{datasets} que todavía no han sido presentados, en el siguiente apartado vamos a detallar la naturaleza y la procedencia de cada uno de ellos como paso previo y necesario a la sección de experimentos propiamente dicha.




\chapter{Experimentos realizados}
\label{cap:experimentosSR}

\pagestyle{headings}

\bigdrop{0pt}{5}{cmr10}A lo largo del texto, se han mostrado ejemplos \ref{ejemplo:basico} \ref{ejemplo:restaurantes} de aplicación del algoritmo \cierree y en general del SR desarrollado, no obstante, en estos momentos en los que contamos con \rse como un SR ya definido, abordamos en este capítulo una serie de experimentos más elaborados que nos permitan comprobar el funcionamiento de nuestro sistema y evaluar su rendimiento. La forma en que vamos a proceder con los experimentos la exponemos a continuación.

Para cada experimento vamos a realizar un test que consiste en simular 100 diálogos siguiendo al pie de la letra el proceso detallado en \ref{seccion:funcionamiento}. No obstante, las simulaciones van a llevarse a cabo como diálogos aleatorios, es decir, cada diálogo se desarrollará eligiendo atributos de forma aleatoria del conjunto de atributos disponible a cada paso de la conversación. Esto puede verse desde diferentes perspectivas. En primera instancia, parece adecuada la estrategia aleatoria ya que así se garantiza la honestidad de los resultados al no haber posibilidad de inducir situaciones favorables para que el sistema obtenga mejores resultados. Sin embargo, proceder de manera aleatoria también puede obscurecer las virtudes de nuestro sistema. 

Por un lado, imaginemos una situación en la que las elecciones aleatorias impliquen atributos que no guardan relación entre ellos en el \textit{dataset}, entonces, el diálogo terminará rápidamente ya que puede que haya muy pocos ítems (o incluso ninguno) que verifiquen tal selección de atributos y por tanto, el proceso terminará sin poder aplicar ninguna reducción de atributos. Ahora bien, supongamos un diálogo más realista en el que la elección de atributos tenga un relación más sensata. En este caso, durante el diálogo, el sistema será capaz de ir aplicando sucesivas podas para reducir la sobrecarga de información ya que existirá relación entre los atributos seleccionados. Por tanto, esta forma de proceder ensalzaría los beneficios de nuestro sistema.

En relación a la evaluación del sistema, las métricas que vamos a utilizar sobre cada simulación van a a ser: número de pasos de la conversación, velocidad de poda de atributos en cada paso y reducción total de atributos; tal y como se han presentado en \ref{seccion:medidasEvaluacion}.

Finalmente, se realizan una serie de repeticiones sobre cada uno de los experimentos de manera que cada número mostrado es fruto de un estudio estadístico a partir de los resultados obtenidos en esas repeticiones que nos permite extraer los resultados más fiables \cite{Goh10}.

Dicho eso, el capítulo va a estar dividido en 4 bloques principales. Comenzaremos con un experimento sobre un \textit{dataset} muy conocido en el campo de los SR: MovieLens10M \ref{seccion:movieLensDatasets}. Es un \textit{dataset} que contiene una gran cantidad de información sobre películas de la que vamos a usar sólo los títulos y géneros. En virtud de esto, trabajamos sobre una cantidad importante de elementos, pero sin contar con demasiados atributos. Continuaremos con otro \textit{dataset} que contiene un menor número de elementos pero muy definidos mediante muchos atributos (Costa del Sol Hotels) y que además contiene información real extraída directamente desde la red \ref{seccion:hotelesCostaDelSol}. Para culminar esta sección, el último experimento utiliza un \textit{dataset} (World Wide POIs) que supera ampliamente a los anteriores en cuanto al número de elementos y atributos y que al igual que el anterior, la información que presenta también es real \ref{seccion:POIsMundial}. 

Finalmente, la última sección nos trae la presentación y los resultados obtenidos sobre el \textit{dataset} \ref{seccion:sintomasDataset} utilizado en una de las publicaciones que avalan esta tesis \cite{Benito-Picazo2017}. Varias tablas y figuras acompañarán cada experimento con la intención de ilustrar más fácilmente los resultados obtenidos. 



\section{MovieLens \textit{datasets}}
\label{seccion:movieLensDatasets}
MovieLens\footnote{http://movielens.org} es un proyecto desarrollado por el equipo de investigación GroupLens\footnote{https://grouplens.org} del Departamento de Ciencias de la Computación e Ingeniería de la Universidad de Minnesota especializado en SR, comunidades online, bibliotecas digitales, ... En su dirección web se ayuda a la gente a elegir películas que deseen ver; grosso modo es un SR de películas con un tinte evidente de CF. Cuenta con cientos de miles de usuarios y de películas almacenadas en una colección muy rica de \textit{datasets} que han sido un referente a la hora de probar el funcionamiento de otros sistemas en diferentes entornos \cite{Harper2016}.

En nuestro caso, nos vamos a centrar en su MovieLens10M \textit{dataset}. Es un \textit{dataset} totalmente accesible de forma gratuíta desde la página web y contiene información de más de 10.000 películas con sus respectivos géneros, duración, país, valoraciones, elenco, etc.%, como muestra la Figura \ref{figura:castilloEnElCielo}.

%\begin{figure}[htbp]
%	\begin{center}
%		\includegraphics[height=.5\textheight,width=.9\textwidth]{castilloEnElCielo.png}
%	\end{center}
%	\caption{Ejemplo de los datos contenidos en la descripción de una película dentro del \textit{dataset} MovieLens 10M.}
%	\label{figura:castilloEnElCielo}
%\end{figure}

De toda esta información, vamos a generar un conjunto reducido para utilizarlo en nuestro \rs. Concretamente, vamos a crear una tabla para emparejar cada una de las películas con todos los posibles géneros que existen en el \textit{dataset} original. De esta forma, tendremos las películas en las filas de la tabla y los géneros como columnas; una película tendrá una marca de verificación en aquellos géneros en los que esté clasificada y nada en otro caso. La Tabla \ref{tabla:MovieLens10M} muestra un pequeño extracto del conjunto final.

\begin{table*}[htbp]
\caption{Extracto del \textit{dataset} MovieLens 10M.}
\label{tabla:MovieLens10M}
\centering
{\scriptsize
\begin{tabular}{lccccccccccccccccccccc}
\hline
Título & Acción & Comedia & Crimen & Drama & Romance & \ldots\\
\hline
Little City (1998) &  & \checkmark &  &   &  \checkmark\\
Driver, The (1978) & \checkmark &  & \checkmark &  &   & \\
Father of the Bride (1950) &  & \checkmark &   & \\
Bio-Dome (1996) &  & \checkmark & &  &   \\
Fast Runner, The (2001) &  &  & & \checkmark &  \\
Overboard (1987) &  & \checkmark &  &  &   \checkmark  \\
Get Rich or Die Tryin' (2005) & \checkmark &  & \checkmark & \checkmark & \\
\ldots\\
\hline
\end{tabular}
}
\end{table*}

Para convertir esta información a valores de 1 ó 0 para nuestro SR sólo tenemos que cambiar los marcas de verificación por 1 y el resto por 0.

Los números de este \textit{dataset} adaptado según se ha indicado, alcanzan los siguientes valores:
\begin{itemize}
	\item Filas (items): 10.681 películas.
	\item Columnas (atributos): 19 géneros.
	\item Implicaciones: 245
\end{itemize}

Con esta información ya estamos en disposición de iniciar la interacción entre el usuario y \rs. No obstante, antes de pasar al experimento general, veamos un ejemplo concreto de diálogo.
\begin{ejemplo}
Supongamos en este caso que el usuario está buscando una película de acción, con experiencia IMAX y con algunos toques de misterio. Entonces, el usuario interactúa con el sistema introduciendo estas preferencias en la conversación. El resultado lo podemos apreciar viendo cuál ha sido diálogo que se ha producido en la Tabla \ref{tabla:ejemploMovieLens10M}.

\begin{table*}[htbp]
\caption{Resultados del diálogo entre \rse y el usuario sobre el \textit{dataset} MovieLens 10M.}
\label{tabla:ejemploMovieLens10M} 
\centering
{\scriptsize
\begin{tabular}{rllrrr}
%\hline
%\multicolumn{6 }{l}{MovieLens10M. Attributes: 19, Associations: 252, Hamacher T-Norm, Threshold: 0.5} \\
%\hline
\hline
Iter. & Selección & Cierre & Atribs. & Implics. & Items\\
\hline
1 & Acción & \{Acción, Thriller, Aventura\} & 16 & 121 & 1.473\\
2 & IMAX & \{Acción, Thriller, Aventura, Sci-Fi, & 12 & 43 & 108\\
 &   & IMAX, Comedia, Fantasía\} &  &  & \\
3 & Misterio & \{Acción, Thriller, Aventura, Sci-Fi, & 8 & 1 & 6\\
 &   & IMAX, Comedia, Fantasía, Misterio &  &  & \\
 &   & Crimen, Romance, Cine-Negro\}\\
\hline
\end{tabular}
}
\end{table*}
\end{ejemplo}

En el ejemplo anterior, podemos darnos cuenta de que incluso cuando interactuamos con un \textit{dataset} muy grande como MovieLens10M, se hace más cómodo para el usuario el obtener una recomendación, ya que en cada paso estamos reduciendo el espacio de búsqueda. Efectivamente, 3 pasos son suficientes para obtener la recomendación entre todo el \textit{dataset}. 

En este sentido, si nos centramos en la primera iteración en la que se introduce la preferencia \textit{Acción}, el conjunto de cierre contiene dos atributos más aparte del seleccionado. La siguiente iteración sigue la misma línea y el cardinal del conjunto cierre aumenta sustancialmente. Como consecuencia, podemos liberar el usuario de tratar con esos atributos en las iteraciones sucesivas, y así estamos reduciendo la sobrecarga de información. Además, como hemos mencionado antes, al mismo tiempo, también reducimos el número de implicaciones involucradas de forma significativa, lo cual acelera las consultas subsiguientes.

\vspace{0.3cm}
Una vez visto un caso concreto de diálogo con este \textit{dataset}, pasamos ahora a realizar el experimento completo tal y como se ha establecido anteriormente, es decir, simulando 100 diálogos diferentes en los cuales los atributos se eligen de forma aleatoria. La Figura \ref{figura:experimentoMovieLens10M} muestra el resultado de este experimento dividido en 3 secciones:
\begin{itemize}
	\item [a)] Representa por medio de un diagrama de sectores el porcentaje de experimentos que han necesitado un determinado número de pasos para alcanzar una recomendación admisible.
	\item [b)] Muestra el porcentaje total de atributos que se han reducido en el diálogo.
	\item [c)] Muestra el porcentaje de atributos que se ha reducido a cada paso de la conversación, es decir, la velocidad de poda.
\end{itemize}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[height=1\textheight,width=.95\textwidth]{experimentoMovieLens10M.png}
	\end{center}
	\caption{Resultado del experimento sobre el \textit{dataset} MovieLens10M.}
	\label{figura:experimentoMovieLens10M}
\end{figure}

Al analizar la Figura \ref{figura:experimentoMovieLens10M}(a) podemos apreciar como \rse es capaz de guiar al usuario hasta una recomendación aceptable en 2 ó 3 pasos en la mayoría de los casos. Si tenemos en cuenta el tamaño de este \textit{dataset}, estos resultados son altamente prometedores.

Respecto a la reducción de atributos global, la Figura \ref{figura:experimentoMovieLens10M}(b) muestra que el sistema ha liberado al usuario de tener que interactuar con el 5-20\% de los atributos. Incluso tenemos algunas pruebas en las que la reducción ha llegado a alcanzar el 60\% de los atributos.

La velocidad de poda acompaña el resultado anterior moviéndose en un rango de entre el 2-10\% como muestra la Figura \ref{figura:experimentoMovieLens10M}(c).

A la luz de estos resultados, podemos concluir que \rse se comporta de forma notable a la hora de aliviar la sobrecarga de información en la interacción con el usuario.

\begin{remark}
Aparte de los \textit{dataset} que podemos encontrar disponibles en la web, a la hora de realizar experimentos nos vimos en la necesidad de poder crear nuestros propios \textit{datasets}, igualmente utilizando información real, pero ahorrando los pasos de análisis y preparación de la información al formato de \rs. 

A raíz de ello, se investigó el \textit{web-scrapping} como una de las técnicas disponibles para extraer información de la red \cite{Bonifacio2015,Johansson2015}. El aprendizaje de esta técnica nos abrió la puerta a crear \textit{datasets} con los que poder trabajar. Como ejemplo de algunos de ellos, tenemos el \textit{dataset} de Hoteles Costa del Sol cuyo experimento pasaremos a analizar, y el de puntos de interés turístico (POIs Mundial) que veremos en la sección \ref{seccion:POIsMundial}.
\end{remark}


\section{Hoteles Costa del Sol \textit{dataset}}
\label{seccion:hotelesCostaDelSol}
Este experimento tiene un gran interés para el usuario ya que la elección de un hotel, ya sea por vacaciones, trabajo o cualquier otro motivo, suele ser una decisión con un alto margen de maniobra en primera instancia. Por lo tanto, contar con un sistema que acelere la búsqueda de nuestras necesidades puede ser muy útil para ahorrar tiempo y esfuerzo. Para ello, presentamos un \textit{dataset} que contiene más de 300 hoteles (extraídos del proyecto Costa del Sol Occidental\footnote{http://www.costadelsoloccidental.org}) cada uno de los cuales con 37 atributos diferentes. Aunque el \textit{dataset} es muy disperso, la tabla final obtenida es digna de tener en consideración ya que está formada por información real que se utiliza actualmente por muchos turistas que visitan el sur de España. 

Al igual que en el experimento anterior, vamos a generar una tabla que contiene los hoteles en las filas y las características o servicios en las columnas tal y como se muestra en la Tabla \ref{tabla:hotelesDataset}.

\begin{table*}[tb]
\caption{Hoteles Costa del Sol \textit{dataset} (extracto)}
\label{tabla:hotelesDataset} 
\centering
{\scriptsize
\begin{tabular}{lcccccccccccccccccccc}
\hline
Nombre Hotel & AC & Bar & Gym & Internet & Masajes & Parking & \ldots\\
\hline
Fuerte Estepona Suites & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark\\
Hotel Buenavista &  & \checkmark &  &  &  & \checkmark \\
Hotel Paraiso & \checkmark & \checkmark &  &  &  & \checkmark \\
Apts Marriot Playa &  &  &  & \checkmark &  &  \\
Hotel Piedra Paloma &  & \checkmark &  &  &  & \checkmark \\
Hostal Hospederia V Cent & \checkmark & \checkmark &  & \checkmark &  & \checkmark \\
\ldots\\
\hline
\end{tabular}
}
\end{table*}

Si bien es cierto que este \textit{dataset} no contiene tantos elementos como el de MovieLens10M \ref{seccion:movieLensDatasets}, sí que lo supera en número de atributos para cada ítem, y aún más importante, en el cardinal del conjunto de implicaciones. Los números finales son:
\begin{itemize}
	\item Filas (items): 361 hoteles.
	\item Columnas (atributos): 37 servicios.
	\item Implicaciones: 1.507
\end{itemize}

Al igual que en el experimento anterior, antes de entrar en el experimento general, veamos un caso concreto. 

\begin{ejemplo}
Supongamos que una pareja joven quiere pasar un fin de semana descansando en un hotel y están visitando sitios web en un teléfono móvil. Los requisitos que buscan por parte del hotel son \textit{Spa} y servicio de \textit{Belleza}. Al introducir estos parámetros en el sistema, se produce un resultado con 16 hoteles. Un resultado así puede ser incómodo para la pantalla de un teléfono móvil común. Sin embargo, consideran incluir una sesión de \textit{Masaje} también, por tanto, añaden la nueva preferencia y obtienen una lista de recomendación con 7 hoteles, eso ya es aceptable. El proceso se representa en la Tabla \ref{tabla:hotelesConversacion}.

\begin{table*}[htbp]
\caption{Resultados del diálogo entre \rse y el usuario sobre el \textit{dataset} Hoteles Costa del Sol}
\label{tabla:hotelesConversacion} 
\centering
{\scriptsize
\begin{tabular}{rllrrr}
%\hline
%\multicolumn{6 }{l}{Costa del Sol Hotels. Attributes: 37, Associations: 3.872, Nilpotent T-Norm, Threshold: 0.1}\\
%\hline
\hline
Iter. & Selección & Cierre & Atribs. & Implics. & Items\\
\hline
1 & Spa & \{Spa, Bar, Restaurante, Cafetería, & 29 & 799 & 96\\
  &     & Piscina, Jardines, Parking, AC\} & & & \\
2 & Belleza & \{Spa, Bar, Restaurante, Cafetería, & 25 & 559 & 16\\
  &     & Piscina, Jardines, Parking, AC\} & & & \\
  &     & Belleza, Reuniones, Deporte, Animación\} & & & \\
3 & Masaje & \{Spa, Bar, Restaurante, Cafetería, & 21 & 126 & 7\\
  &     & Piscina, Jardines, Parking, AC, & & & \\
  &     & Belleza, Reuniones, Deporte, Animación, & & & \\
  &     & Masaje, Médico, Lavandería, Internet\} & & & \\
\hline
\end{tabular}
}
\end{table*}
\end{ejemplo}

En este experimento se aprecia claramente cómo el mecanismo de poda hace que la interacción sea más rápida, más cómoda y dinámica, ya que podría ser una ardua tarea tratar de elegir por un hotel entre cientos de posibilidades con más de 30 servicios posibles cada una. Por el contrario, 3 pasos son suficientes para guiar a la pareja
a sus mejores opciones. Estos resultados superan con creces los estudios previos \cite{TrabelsiWBR11} donde, incluso contando con un \textit{dataset} hotelero más pequeño, el número de pasos necesarios es mayor.


Con la intención de preservar la completitud con el experimento anterior, la Figura \ref{figura:experimentoHotelesQualifica} muestra el resultado para el experimento completo.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[height=1\textheight,width=.95\textwidth]{experimentoHotelesQualifica.png}
	\end{center}
	\caption{Resultado del experimento sobre el \textit{dataset} Hoteles Costa del Sol.}
	\label{figura:experimentoHotelesQualifica}
\end{figure}

Respecto a este experimento, podemos ver que los resultados son ligeramente diferentes a los alcanzados sobre MovieLens10M \ref{figura:experimentoMovieLens10M}. El primer punto notable del experimento es que esta vez hay casos en que la duración de la conversación ha aumentado y esto se debe a que el número de atributos posibles es mucho mayor ahora. Aún así, en la mayoría de los casos son necesarios sólo 2-3 pasos una vez más para conseguir una recomendación admisible.

La reducción de atributos es mayor en este caso con respecto a MovieLens10M, alcanzando tasas de poda entre 10-40\% en la mayoría de los casos, y de entorno al 85\% en algunos otros. 

Del mismo modo, la velocidad de poda también es mayor como podemos apreciar en la Figura \ref{figura:experimentoHotelesQualifica}(c); en definitiva, consiguiendo valores que reflejan la utilidad del mecanismo de conversacional.



\section{POIs Mundial \textit{dataset}}
\label{seccion:POIsMundial}
Finalmente, con la intención de crear un \textit{datasete} más amplio que los anteriores tanto en el número de ítems como en el número de atributos, llegamos al último \textit{dataset} generado, al cual hemos denominado POIs Mundial \textit{dataset}. Manteniendo la idea de realizar pruebas más fidedignas, la información del \textit{dataset} es información real, extraída del portal web Tripadvisor\footnote{https://www.tripadvisor.es} con las técnicas mencionadas anteriormente. Este \textit{dataset} va a contener información de multitud de puntos de interés (en inglés \textit{Points Of Interest}) turístico de todo el mundo (Torre Eiffel, Estatua de la Libertad, Big Ben, Plaza Roja, Coliseo, etc.). En esta clasificación entran monumentos, parques, museos, iglesias, galerías de arte, teatros, complejos deportivos, ..., así hasta un total de más de 100 categorías diferentes. En la Figura \ref{figura:poisRoma} mostramos un ejemplo de algunos de los puntos de interés que podemos encontrar en Roma según la web y las categorías a las que pertenecen.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[height=.4\textheight,width=1\textwidth]{poisRoma.png}
	\end{center}
	\caption{Ejemplo de puntos de interés de la ciudad de Roma que muestra el portal Tripadvisor. En la parte inferior de cada uno podemos ver a qué grupo pertenece (Iglesias, Monumentos, Estatuas, Fuentes, ...).}
	\label{figura:poisRoma}
\end{figure}

La generación de este \textit{dataset} arrojó una serie de resultados muy satisfactorios. El primero fue constatar la capacidad adquirida para la generación de \textit{datasets} de gran envergadura y con información real. De hecho POIs Mundial con un total de 17.400 puntos de interés (ítems), cantidad que sobrepasa notablemente a las 10.000 películas almacenadas en el histórico \textit{dataset} de MovieLens10 analizado en \ref{seccion:movieLensDatasets}. Además, cada elemento puede pertenecer a más de 100 categorías diferentes (en concreto 115 categorías diferentes), lo cual genera una tabla con un total de más de 2 millones de celdas. Aún así, el número de implicaciones generado no es excesivo debido a que el conjunto es altamente disperso. 

En resumen, los números para este último \textit{dataset} son:
\begin{itemize}
	\item Filas (items): 17.400
	\item Columnas (atributos): 115
	\item Implicaciones: 675
\end{itemize}

Pasamos ahora comprobar el resultado obtenido tras lanzar el test sobre el mayor de los \textit{datasets} generados en esta investigación.

Recordemos ahora que estamos tratando con un \textit{dataset} que contiene más de 17.000 puntos de interés que pueden verificar más de 100 atributos diferentes. Si bien los números de este \textit{dataset} son mayores que los de el \textit{dataset} MovieLens10M, vemos que los resultados obtenidos, \textit{a priori} parecen aún más espectaculares (2 ó 3 pasos en la conversación). Sin embargo, en este caso tenemos que hacer unas aclaraciones.

Al principio de este apartado indicábamos que los tests se llevarían a cabo simulando diálogos donde los atributos se seleccionarían de forma aleatoria y analizamos los pros y contras de esta decisión. Bien, pues experimento pone en evidencia tales circunstancias. Por un lado, vemos como la mayoría de los test finalizan en 2 ó 3 pasos de conversación (ver Figura \ref{figura:experimentoPOIsMundial}(a)). Esto puede considerarse un gran éxito del sistema al necesitar un diálogo tan corto a la hora de hacer una recomendación entre tantísimos elementos, y de hecho en muchos de los tests la situación se refleja fielmente. 

Sin embargo, algunos otros experimentos que también han terminado tan rápido, se debe a que la selección de atributos no ha sido coherente. Por ejemplo, supongamos que entre todos los atributos se ha seleccionado que el punto de interés sea del tipo \textit{Museo Histórico} y \textit{Playas}, entonces a la hora de buscar elementos del \textit{dataset} que verifiquen simultáneamente atributos tan dispares, el resultado contendrá muy pocos elementos y por tanto en pocos pasos habremos finalizado el diálogo. En definitiva, esto sucede debido a dos razones fundamentales: 
\begin{enumerate}
	\item La selección aleatoria de atributos.
	\item Y muy importante, el \textit{dataset} es altamente disperso, ya que de entre los más de 100 atributos posibles, un punto de interés llega a verificar simultáneamente a la sumo 7 de ellos.
\end{enumerate}

Por otro lado, en la Figura \ref{figura:experimentoPOIsMundial}(b) y (c) podemos apreciar que en este caso la reducción de atributos y la velocidad de poda alcanzan niveles aún más notables que en el caso de MovieLens10M, y es que aunque los valores sean similares (reducción entre el 5-25\% y velocidad de poda entre el 2-10\%), hay que tener en cuenta que debido al tamaño de este \textit{dataset}, esos porcentajes implican un número de elementos eliminados muy superior.

En resumen, podemos constatar que incluso con \textit{datasets} tan ricos en contenido, \rse es capaz de entablar un diálogo con el usuario brindándole unas reducciones de información muy importantes, aliviando de esta forma de manera notable la sobrecarga de información.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[height=1\textheight,width=.9\textwidth]{experimentoPOIsMundial.png}
	\end{center}
	\caption{Resultado del experimento sobre el \textit{dataset} POIs Mundial.}
	\label{figura:experimentoPOIsMundial}
\end{figure} 



%\section{Otros experimentos}
%\label{seccion:otrosExperimentos}
%Hasta ahora y como mencionamos al principio de este capítulo, hemos analizado el resultado de las pruebas para 3 tipos diferentes de \textit{dataset} en cuanto a contenido y características relacionadas con el funcionamiento de \rs. Estos resultados han demostrado claramente la operatividad de \rse y el progreso alcanzado en cuanto al tratamiento del problema de la dimensionalidad en las recomendaciones.

%No obstante, durante la realización de esta tesis se han realizado otros experimentos similares que, si bien no vamos a analizar al mismo nivel de detalle por ser parecidos a los ya expuestos, les dedicaremos una breve reseña.

\section{Enfermedades y Síntomas \textit{dataset}}
\label{seccion:sintomasDataset}
Otro de los \textit{datasets} generados es el que hemos denominado por cuenta propia \textit{Diseases \& Symptoms dataset}. Este \textit{dataset} tiene una importancia mayor ya que ha sido el utilizado en una de las publicaciones que avalan esta Tesis Doctoral \cite{Benito-Picazo2017}. A continuación, pasamos a describir la fuente de los datos y la estructura del \textit{dataset} generado.

La fuente original de la cual se ha extraído la información es el Phenotype Ontology Consortium\footnote{http://www.human-phenotype-ontology.org} (HPO). Como podemos leer en su página web: ``HPO \footnote{HumanPhenotypeOntology} pretende proveer un lenguaje estandarizado de las fenotipos encontrados por anomalías en enfermedades humanas. Cada término en HPO describe una anomalía fenotípica. HPO está en desarrollo utilizando literatura médica, Orphanet\footnote{http://www.orpha.net/consor/cgi-bin/index.php}, DECIPHER\footnote{https://decipher.sanger.ac.uk}, y Online Mendelian Inheritance in Man (OMIM)\footnote{http://www.omim.org}.''.  A partir de toda esta información pudimos generar un \textit{dataset} sobre el que desempeñar nuestros experimentos. 

Debido a que la cantidad de información en el HPO es enorme, en esta primera aproximación sólo vamos a utilizar un extracto de toda la información disponible. Haciendo uso de OMIM para diferenciar entre diferentes tipos de fenotipos que aparecen en el HPO, hemos generado una tabla que empareja anomalías hematológicas y fenotipos, consiguiendo un conjunto de datos considerable. Podemos ver un extracto de la información generada en la Tabla \ref{table:diseases}.

\begin{table*}[htbp]
\caption{Diseases \& Symptoms dataset (extract)}
\label{table:diseases} \centering
{\scriptsize
\begin{tabular}{lccccccc}
\hline
Disease ID & HPO\_1249 & HPO\_1250 & HPO\_1251 & HPO\_1252 & HPO\_1254 & \ldots\\
\hline
274000 &  & \checkmark &  &   & \\
%275350 & X &  & X &  & X & \\
275630 & \checkmark &  & \checkmark & & \\
277380 &  &  &  & \checkmark & \checkmark \\
%277400 & X & X & & X & X & \\
%300653 & X & X & X &  &  & \\
300884 &  & \checkmark &  & \checkmark &  \\
300322 & \checkmark &  &  & \checkmark &  \\
\ldots\\
\hline
\end{tabular}
}
\end{table*}

En caso de que queramos obtener información detallada de cada anomalía que se muestra, encomendamos al lector a visitar la web de OMIM y utilizar su motor de búsqueda con el identificador mostrado en la columna \textit{Disease ID}. Como ejemplo, la anomalía \textit{Disease ID 275630} corresponde con el síndrome \textit{Chanarin-Dorfman}.

En definitiva, vamos a trabajar sobre un \textit{dataset} con 446 enfermedades, 100 fenotipos diferentes y todas las implicaciones que se verifican. Desgraciadamente, no podemos mostrarlas todas en el documento pues el conjunto alcanza un número superior a 6.000 implicaciones. 

Este experimento además de su relevancia en cuanto a figurar en una de las publicaciones que avalan esta tesis \cite{Benito-Picazo2017}, tiene una importancia añadida debido al alto número de implicaciones que contiene. Recordemos que en un \textit{dataset} de referencia en el campo como lo es MovieLens10M \ref{seccion:movieLensDatasets} el número de implicaciones que obteníamos era 245, mientras que ahora \rse trabajará y con resultados satisfactorios, con este \textit{dataset} en el que el cardinal del conjunto de implicaciones es superior a 6.000 implicaciones.

A continuación recopilamos los números de este \textit{dataset}:

\begin{itemize}
	\item Filas (items): 446 anomalías.
	\item Columnas (atributos): 100 fenotipos.
	\item Implicaciones: 6.468
\end{itemize}

En este punto tenemos que hacer un inciso importante y que es de aplicación para todos los \textit{datasets} y pruebas que se han realizado.

\begin{remark}
Si nos centramos en el Enfermedades y Síntomas \textit{dataset} y calculamos la llamada base Duquenne-Guigues \cite{Guigues1986} de implicaciones que se verifican en el contexto, el número de implicaciones asciende hasta las 8.811 implicaciones. Entonces, ¿por qué hablamos de que el sistema va a tratar unas 6.000 implicaciones con este \textit{dataset}? Bien, pues la principal característica de la base Duquenne-Guigues de implicaciones es que esta base tiene el menor número de implicaciones posibles entre todas las posibles bases de implicaciones que se verifican en el contexto. Sin embargo, existirán algunas implicaciones para las que no haya ningún objeto que las verifique, y esas implicaciones significan que el conjunto de objetos que pueden cumplir con la premisa de la regla, no existen en el contexto. Además, esas implicaciones incluyen todos los atributos del contexto. Por tanto, el sentido de esas implicaciones es simplemente teórico y no presenta ningún valor cuando estamos tratando con aplicaciones reales; es por ello por lo que obviamos tales implicaciones.
\end{remark}

En este caso, los resultados del experimento y sus conclusiones pueden consultarse en \cite{Benito-Picazo2017}.

% =====================================================================
% =====================================================================
% =====================================================================


